{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import pickle \n",
    "import numpy as np \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "import data\n",
    "import scipy.io\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from etm import ETM\n",
    "from utils import nearest_neighbors, get_topic_coherence, get_topic_diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    description='The Embedded Topic Model'\n",
    "    dataset = 'ah20k'\n",
    "    data_path = 'data/ah20k'\n",
    "    emb_path = 'data/ah20k_embeddings.txt'\n",
    "    save_path = './results'\n",
    "    batch_size = 1000\n",
    "\n",
    "    ### model-related arguments\n",
    "    num_topics = 5\n",
    "    rho_size = 300\n",
    "    emb_size = 300\n",
    "    t_hidden_size = 800\n",
    "    theta_act = 'relu'\n",
    "    train_embeddings = 1 #\n",
    "\n",
    "    ### optimization-related arguments\n",
    "    lr= 0.005\n",
    "    lr_factor = 4.0\n",
    "    epochs = 200\n",
    "    mode = 'train'\n",
    "    optimizer = 'adam'\n",
    "    seed = 2019\n",
    "    enc_drop = 0.0\n",
    "    clip = 0.0\n",
    "    nonmono = 10\n",
    "    wdecay = 1.2e-6\n",
    "    anneal_lr = 0\n",
    "    bow_norm = 1\n",
    "\n",
    "    ### evaluation, visualization, and logging-related arguments\n",
    "    num_words = 10\n",
    "    log_interval = 2\n",
    "    visualize_every = 10\n",
    "    eval_batch_size = 1000\n",
    "    load_from = ''\n",
    "    tc = True\n",
    "    td = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "## get data\n",
    "# 1. vocabulary\n",
    "vocab, train, valid, test = data.get_data(os.path.join(args.data_path))\n",
    "vocab_size = len(vocab)\n",
    "args.vocab_size = vocab_size\n",
    "\n",
    "# 1. training data\n",
    "train_tokens = train['tokens']\n",
    "train_counts = train['counts']\n",
    "args.num_docs_train = len(train_tokens)\n",
    "\n",
    "# 2. dev set\n",
    "valid_tokens = valid['tokens']\n",
    "valid_counts = valid['counts']\n",
    "args.num_docs_valid = len(valid_tokens)\n",
    "\n",
    "# 3. test data\n",
    "test_tokens = test['tokens']\n",
    "test_counts = test['counts']\n",
    "args.num_docs_test = len(test_tokens)\n",
    "test_1_tokens = test['tokens_1']\n",
    "test_1_counts = test['counts_1']\n",
    "args.num_docs_test_1 = len(test_1_tokens)\n",
    "test_2_tokens = test['tokens_2']\n",
    "test_2_counts = test['counts_2']\n",
    "args.num_docs_test_2 = len(test_2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
      "Training an Embedded Topic Model on AH20K with the following settings: <__main__.Args object at 0x7f55e9d0b310>\n",
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n"
     ]
    }
   ],
   "source": [
    "embeddings = None\n",
    "if not args.train_embeddings:\n",
    "    emb_path = args.emb_path\n",
    "    vect_path = os.path.join(args.data_path.split('/')[0], 'embeddings.pkl')   \n",
    "    vectors = {}\n",
    "    with open(emb_path, 'rb') as f:\n",
    "        for l in f:\n",
    "            line = l.decode().split()\n",
    "            word = line[0]\n",
    "            if word in vocab:\n",
    "                vect = np.array(line[1:]).astype(np.float)\n",
    "                vectors[word] = vect\n",
    "    embeddings = np.zeros((vocab_size, args.emb_size))\n",
    "    words_found = 0\n",
    "    for i, word in enumerate(vocab):\n",
    "        try: \n",
    "            embeddings[i] = vectors[word]\n",
    "            words_found += 1\n",
    "        except KeyError:\n",
    "            embeddings[i] = np.random.normal(scale=0.6, size=(args.emb_size, ))\n",
    "    embeddings = torch.from_numpy(embeddings).to(device)\n",
    "    args.embeddings_dim = embeddings.size()\n",
    "\n",
    "print('=*'*100)\n",
    "print('Training an Embedded Topic Model on {} with the following settings: {}'.format(args.dataset.upper(), args))\n",
    "print('=*'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ETM(\n",
      "  (t_drop): Dropout(p=0.0, inplace=False)\n",
      "  (theta_act): ReLU()\n",
      "  (rho): Linear(in_features=300, out_features=3951, bias=False)\n",
      "  (alphas): Linear(in_features=300, out_features=5, bias=False)\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=3951, out_features=800, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=800, out_features=5, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=800, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## define checkpoint\n",
    "if not os.path.exists(args.save_path):\n",
    "    os.makedirs(args.save_path)\n",
    "\n",
    "if args.mode == 'eval':\n",
    "    ckpt = args.load_from\n",
    "else:\n",
    "    ckpt = os.path.join(args.save_path, \n",
    "        'etm_{}_K_{}_Htheta_{}_Optim_{}_Clip_{}_ThetaAct_{}_Lr_{}_Bsz_{}_RhoSize_{}_trainEmbeddings_{}'.format(\n",
    "        args.dataset, args.num_topics, args.t_hidden_size, args.optimizer, args.clip, args.theta_act, \n",
    "            args.lr, args.batch_size, args.rho_size, args.train_embeddings))\n",
    "\n",
    "## define model and optimizer\n",
    "model = ETM(args.num_topics, vocab_size, args.t_hidden_size, args.rho_size, args.emb_size, \n",
    "                args.theta_act, embeddings, args.train_embeddings, args.enc_drop).to(device)\n",
    "\n",
    "print('model: {}'.format(model))\n",
    "\n",
    "if args.optimizer == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wdecay)\n",
    "elif args.optimizer == 'adagrad':\n",
    "    optimizer = optim.Adagrad(model.parameters(), lr=args.lr, weight_decay=args.wdecay)\n",
    "elif args.optimizer == 'adadelta':\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr, weight_decay=args.wdecay)\n",
    "elif args.optimizer == 'rmsprop':\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.wdecay)\n",
    "elif args.optimizer == 'asgd':\n",
    "    optimizer = optim.ASGD(model.parameters(), lr=args.lr, t0=0, lambd=0., weight_decay=args.wdecay)\n",
    "else:\n",
    "    print('Defaulting to vanilla SGD')\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    acc_loss = 0\n",
    "    acc_kl_theta_loss = 0\n",
    "    cnt = 0\n",
    "    indices = torch.randperm(args.num_docs_train)\n",
    "    indices = torch.split(indices, args.batch_size)\n",
    "    for idx, ind in enumerate(indices):\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        data_batch = data.get_batch(train_tokens, train_counts, ind, args.vocab_size, device)\n",
    "        sums = data_batch.sum(1).unsqueeze(1)\n",
    "        if args.bow_norm:\n",
    "            normalized_data_batch = data_batch / sums\n",
    "        else:\n",
    "            normalized_data_batch = data_batch\n",
    "        recon_loss, kld_theta = model(data_batch, normalized_data_batch)\n",
    "        total_loss = recon_loss + kld_theta\n",
    "        total_loss.backward()\n",
    "\n",
    "        if args.clip > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        acc_loss += torch.sum(recon_loss).item()\n",
    "        acc_kl_theta_loss += torch.sum(kld_theta).item()\n",
    "        cnt += 1\n",
    "\n",
    "        if idx % args.log_interval == 0 and idx > 0:\n",
    "            cur_loss = round(acc_loss / cnt, 2) \n",
    "            cur_kl_theta = round(acc_kl_theta_loss / cnt, 2) \n",
    "            cur_real_loss = round(cur_loss + cur_kl_theta, 2)\n",
    "\n",
    "            print('Epoch: {} .. batch: {}/{} .. LR: {} .. KL_theta: {} .. Rec_loss: {} .. NELBO: {}'.format(\n",
    "                epoch, idx, len(indices), optimizer.param_groups[0]['lr'], cur_kl_theta, cur_loss, cur_real_loss))\n",
    "    \n",
    "    cur_loss = round(acc_loss / cnt, 2) \n",
    "    cur_kl_theta = round(acc_kl_theta_loss / cnt, 2) \n",
    "    cur_real_loss = round(cur_loss + cur_kl_theta, 2)\n",
    "    print('*'*100)\n",
    "    print('Epoch----->{} .. LR: {} .. KL_theta: {} .. Rec_loss: {} .. NELBO: {}'.format(\n",
    "            epoch, optimizer.param_groups[0]['lr'], cur_kl_theta, cur_loss, cur_real_loss))\n",
    "    print('*'*100)\n",
    "\n",
    "def visualize(m, show_emb=True):\n",
    "    if not os.path.exists('./results'):\n",
    "        os.makedirs('./results')\n",
    "\n",
    "    m.eval()\n",
    "\n",
    "    queries = ['cleaner', 'refrigerate', 'tupperware', 'curry', 'baby', 'weather', 'buffet', \n",
    "                            'ninja', 'fingernail']\n",
    "\n",
    "    ## visualize topics using monte carlo\n",
    "    with torch.no_grad():\n",
    "        print('#'*100)\n",
    "        print('Visualize topics...')\n",
    "        topics_words = []\n",
    "        gammas = m.get_beta()\n",
    "        for k in range(args.num_topics):\n",
    "            gamma = gammas[k]\n",
    "            top_words = list(gamma.cpu().numpy().argsort()[-args.num_words+1:][::-1])\n",
    "            topic_words = [vocab[a] for a in top_words]\n",
    "            topics_words.append(' '.join(topic_words))\n",
    "            print('Topic {}: {}'.format(k, topic_words))\n",
    "\n",
    "        if show_emb:\n",
    "            ## visualize word embeddings by using V to get nearest neighbors\n",
    "            print('#'*100)\n",
    "            print('Visualize word embeddings by using output embedding matrix')\n",
    "            try:\n",
    "                embeddings = m.rho.weight  # Vocab_size x E\n",
    "            except:\n",
    "                embeddings = m.rho         # Vocab_size x E\n",
    "            neighbors = []\n",
    "            for word in queries:\n",
    "                print('word: {} .. neighbors: {}'.format(\n",
    "                    word, nearest_neighbors(word, embeddings, vocab)))\n",
    "            print('#'*100)\n",
    "\n",
    "def evaluate(m, source, tc=False, td=False):\n",
    "    \"\"\"Compute perplexity on document completion.\n",
    "    \"\"\"\n",
    "    m.eval()\n",
    "    with torch.no_grad():\n",
    "        if source == 'val':\n",
    "            indices = torch.split(torch.tensor(range(args.num_docs_valid)), args.eval_batch_size)\n",
    "            tokens = valid_tokens\n",
    "            counts = valid_counts\n",
    "        else: \n",
    "            indices = torch.split(torch.tensor(range(args.num_docs_test)), args.eval_batch_size)\n",
    "            tokens = test_tokens\n",
    "            counts = test_counts\n",
    "\n",
    "        ## get \\beta here\n",
    "        beta = m.get_beta()\n",
    "\n",
    "        ### do dc and tc here\n",
    "        acc_loss = 0\n",
    "        cnt = 0\n",
    "        indices_1 = torch.split(torch.tensor(range(args.num_docs_test_1)), args.eval_batch_size)\n",
    "        for idx, ind in enumerate(indices_1):\n",
    "            ## get theta from first half of docs\n",
    "            data_batch_1 = data.get_batch(test_1_tokens, test_1_counts, ind, args.vocab_size, device)\n",
    "            sums_1 = data_batch_1.sum(1).unsqueeze(1)\n",
    "            if args.bow_norm:\n",
    "                normalized_data_batch_1 = data_batch_1 / sums_1\n",
    "            else:\n",
    "                normalized_data_batch_1 = data_batch_1\n",
    "            theta, _ = m.get_theta(normalized_data_batch_1)\n",
    "\n",
    "            ## get prediction loss using second half\n",
    "            data_batch_2 = data.get_batch(test_2_tokens, test_2_counts, ind, args.vocab_size, device)\n",
    "            sums_2 = data_batch_2.sum(1).unsqueeze(1)\n",
    "            res = torch.mm(theta, beta)\n",
    "            preds = torch.log(res)\n",
    "            recon_loss = -(preds * data_batch_2).sum(1)\n",
    "            \n",
    "            loss = recon_loss / sums_2.squeeze()\n",
    "            loss = loss.mean().item()\n",
    "            acc_loss += loss\n",
    "            cnt += 1\n",
    "        cur_loss = acc_loss / cnt\n",
    "        ppl_dc = round(math.exp(cur_loss), 1)\n",
    "        print('*'*100)\n",
    "        print('{} Doc Completion PPL: {}'.format(source.upper(), ppl_dc))\n",
    "        print('*'*100)\n",
    "        if tc or td:\n",
    "            beta = beta.data.cpu().numpy()\n",
    "            if tc:\n",
    "                print('Computing topic coherence...')\n",
    "                get_topic_coherence(beta, train_tokens, vocab)\n",
    "            if td:\n",
    "                print('Computing topic diversity...')\n",
    "                get_topic_diversity(beta, 25)\n",
    "        return ppl_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Visualizing model quality before training...\n",
      "####################################################################################################\n",
      "Visualize topics...\n",
      "Topic 0: ['fingernail', 'slender', 'veggie', 'collector', 'weakness', 'latest', 'struggle', 'inaccurate', 'cleaner']\n",
      "Topic 1: ['refrigerate', 'crusher', 'outdoors', 'custard', 'snob', 'specific', 'hint', 'nuisance', 'weather']\n",
      "Topic 2: ['abit', 'junky', 'command', 'critter', 'perform', 'consume', 'thrill', 'arise', 'pull']\n",
      "Topic 3: ['afraid', 'soooo', 'shiny', 'recipient', 'tupperware', 'shag', 'simmer', 'suitable', 'robust']\n",
      "Topic 4: ['write', 'anymore', 'pocket', 'removeable', 'anticipate', 'curry', 'catcher', 'ikea', 'fibrox']\n",
      "####################################################################################################\n",
      "Visualize word embeddings by using output embedding matrix\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: cleaner .. neighbors: ['cleaner', 'diameter', 'keeper', 'drill', 'fixture', 'fancier', 'tremendous', 'navy', 'drywall', 'criterion', 'country', 'jumbo', 'crinkle', 'divide', 'content', 'softer', 'sell', 'drawback', 'buffet', 'brain']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: refrigerate .. neighbors: ['refrigerate', 'agent', 'chuck', 'crop', 'vibration', 'bistro', 'attempt', 'notice', 'smaller', 'incorrect', 'caveat', 'muddle', 'wasnt', 'curve', 'spinach', 'rare', 'boneless', 'plate', 'collapsible', 'sculpture']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: tupperware .. neighbors: ['tupperware', 'silpat', 'yank', 'breakage', 'sodastream', 'jealous', 'shear', 'breath', 'weighty', 'prefer', 'impact', 'install', 'hooray', 'soap', 'patient', 'accessible', 'amateur', 'sauerkraut', 'chemical', 'sprayer']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: curry .. neighbors: ['curry', 'liquor', 'smudge', 'extension', 'path', 'crowd', 'removeable', 'pestle', 'straight', 'gonna', 'ache', 'holiday', 'drop', 'criterion', 'bump', 'brim', 'peeler', 'watermelon', 'application', 'inaccurate']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: baby .. neighbors: ['baby', 'show', 'user', 'culture', 'ronco', 'reassemble', 'touch', 'fact', 'storm', 'puck', 'coarse', 'inch', 'inspect', 'omelet', 'perimeter', 'sunbeam', 'relationship', 'impress', 'brewer', 'lead']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: weather .. neighbors: ['weather', 'leech', 'hardware', 'culture', 'consumption', 'disk', 'experience', 'heart', 'acceptable', 'drive', 'slap', 'unhappy', 'condensation', 'cruise', 'puck', 'preserve', 'kitty', 'apple', 'slimy', 'quinoa']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: buffet .. neighbors: ['buffet', 'sand', 'stationary', 'cosmetic', 'silpat', 'street', 'slice', 'cheap', 'glide', 'spout', 'attempt', 'soggy', 'scrape', 'affordable', 'mark', 'wash', 'registry', 'total', 'tremendous', 'trash']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: ninja .. neighbors: ['ninja', 'crap', 'canister', 'bullet', 'leakage', 'lumpy', 'hazard', 'pickup', 'check', 'neat', 'linger', 'grow', 'fluffy', 'funnel', 'crumb', 'steak', 'develop', 'flavor', 'wise', 'canola']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: fingernail .. neighbors: ['fingernail', 'wrist', 'manufacturer', 'neighbor', 'experience', 'timely', 'goody', 'inspect', 'swap', 'duct', 'razor', 'prime', 'king', 'fingerprint', 'flaw', 'soft', 'avocado', 'unusable', 'teeny', 'fluff']\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "Epoch: 1 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 136.02 .. NELBO: 136.03\n",
      "Epoch: 1 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 136.25 .. NELBO: 136.26\n",
      "Epoch: 1 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 135.17 .. NELBO: 135.18\n",
      "Epoch: 1 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 134.09 .. NELBO: 134.1\n",
      "Epoch: 1 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 132.95 .. NELBO: 132.96\n",
      "Epoch: 1 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 131.58 .. NELBO: 131.59\n",
      "****************************************************************************************************\n",
      "Epoch----->1 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 130.53 .. NELBO: 130.54\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 1336.9\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ETM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/william/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/william/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/william/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/william/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 117.93 .. NELBO: 117.93\n",
      "Epoch: 2 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 116.52 .. NELBO: 116.52\n",
      "Epoch: 2 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 117.13 .. NELBO: 117.13\n",
      "Epoch: 2 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 117.31 .. NELBO: 117.31\n",
      "Epoch: 2 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 117.24 .. NELBO: 117.24\n",
      "Epoch: 2 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 117.4 .. NELBO: 117.4\n",
      "****************************************************************************************************\n",
      "Epoch----->2 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 117.5 .. NELBO: 117.5\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 1047.3\n",
      "****************************************************************************************************\n",
      "Epoch: 3 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 115.02 .. NELBO: 115.02\n",
      "Epoch: 3 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 115.11 .. NELBO: 115.11\n",
      "Epoch: 3 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 114.95 .. NELBO: 114.95\n",
      "Epoch: 3 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 115.26 .. NELBO: 115.26\n",
      "Epoch: 3 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 115.5 .. NELBO: 115.5\n",
      "Epoch: 3 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.0 .. Rec_loss: 115.76 .. NELBO: 115.76\n",
      "****************************************************************************************************\n",
      "Epoch----->3 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 115.97 .. NELBO: 115.98\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 1026.7\n",
      "****************************************************************************************************\n",
      "Epoch: 4 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 114.35 .. NELBO: 114.36\n",
      "Epoch: 4 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 114.96 .. NELBO: 114.97\n",
      "Epoch: 4 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 114.9 .. NELBO: 114.91\n",
      "Epoch: 4 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 114.99 .. NELBO: 115.0\n",
      "Epoch: 4 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 115.44 .. NELBO: 115.45\n",
      "Epoch: 4 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 115.62 .. NELBO: 115.63\n",
      "****************************************************************************************************\n",
      "Epoch----->4 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 115.59 .. NELBO: 115.6\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 1009.7\n",
      "****************************************************************************************************\n",
      "Epoch: 5 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.01 .. Rec_loss: 116.8 .. NELBO: 116.81\n",
      "Epoch: 5 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 116.49 .. NELBO: 116.51\n",
      "Epoch: 5 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 115.94 .. NELBO: 115.96\n",
      "Epoch: 5 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 115.94 .. NELBO: 115.96\n",
      "Epoch: 5 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 115.63 .. NELBO: 115.65\n",
      "Epoch: 5 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 115.4 .. NELBO: 115.42\n",
      "****************************************************************************************************\n",
      "Epoch----->5 .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 115.52 .. NELBO: 115.54\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 1007.3\n",
      "****************************************************************************************************\n",
      "Epoch: 6 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.02 .. Rec_loss: 113.69 .. NELBO: 113.71\n",
      "Epoch: 6 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.03 .. Rec_loss: 114.19 .. NELBO: 114.22\n",
      "Epoch: 6 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.03 .. Rec_loss: 114.8 .. NELBO: 114.83\n",
      "Epoch: 6 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.03 .. Rec_loss: 115.09 .. NELBO: 115.12\n",
      "Epoch: 6 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.03 .. Rec_loss: 114.99 .. NELBO: 115.02\n",
      "Epoch: 6 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.03 .. Rec_loss: 115.4 .. NELBO: 115.43\n",
      "****************************************************************************************************\n",
      "Epoch----->6 .. LR: 0.005 .. KL_theta: 0.03 .. Rec_loss: 115.49 .. NELBO: 115.52\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 1006.3\n",
      "****************************************************************************************************\n",
      "Epoch: 7 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.03 .. Rec_loss: 114.89 .. NELBO: 114.92\n",
      "Epoch: 7 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.03 .. Rec_loss: 115.11 .. NELBO: 115.14\n",
      "Epoch: 7 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.04 .. Rec_loss: 115.65 .. NELBO: 115.69\n",
      "Epoch: 7 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.04 .. Rec_loss: 115.64 .. NELBO: 115.68\n",
      "Epoch: 7 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.04 .. Rec_loss: 115.55 .. NELBO: 115.59\n",
      "Epoch: 7 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.04 .. Rec_loss: 115.58 .. NELBO: 115.62\n",
      "****************************************************************************************************\n",
      "Epoch----->7 .. LR: 0.005 .. KL_theta: 0.04 .. Rec_loss: 115.46 .. NELBO: 115.5\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 1004.9\n",
      "****************************************************************************************************\n",
      "Epoch: 8 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.05 .. Rec_loss: 115.34 .. NELBO: 115.39\n",
      "Epoch: 8 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.05 .. Rec_loss: 115.78 .. NELBO: 115.83\n",
      "Epoch: 8 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.05 .. Rec_loss: 115.81 .. NELBO: 115.86\n",
      "Epoch: 8 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.05 .. Rec_loss: 115.31 .. NELBO: 115.36\n",
      "Epoch: 8 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.05 .. Rec_loss: 115.08 .. NELBO: 115.13\n",
      "Epoch: 8 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.05 .. Rec_loss: 115.35 .. NELBO: 115.4\n",
      "****************************************************************************************************\n",
      "Epoch----->8 .. LR: 0.005 .. KL_theta: 0.05 .. Rec_loss: 115.47 .. NELBO: 115.52\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 1005.0\n",
      "****************************************************************************************************\n",
      "Epoch: 9 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.06 .. Rec_loss: 114.2 .. NELBO: 114.26\n",
      "Epoch: 9 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.06 .. Rec_loss: 114.06 .. NELBO: 114.12\n",
      "Epoch: 9 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.06 .. Rec_loss: 114.2 .. NELBO: 114.26\n",
      "Epoch: 9 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.06 .. Rec_loss: 115.04 .. NELBO: 115.1\n",
      "Epoch: 9 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.06 .. Rec_loss: 115.31 .. NELBO: 115.37\n",
      "Epoch: 9 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.06 .. Rec_loss: 115.23 .. NELBO: 115.29\n",
      "****************************************************************************************************\n",
      "Epoch----->9 .. LR: 0.005 .. KL_theta: 0.06 .. Rec_loss: 115.45 .. NELBO: 115.51\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 1004.5\n",
      "****************************************************************************************************\n",
      "Epoch: 10 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.08 .. Rec_loss: 116.05 .. NELBO: 116.13\n",
      "Epoch: 10 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.07 .. Rec_loss: 115.83 .. NELBO: 115.9\n",
      "Epoch: 10 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.07 .. Rec_loss: 115.54 .. NELBO: 115.61\n",
      "Epoch: 10 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.08 .. Rec_loss: 115.5 .. NELBO: 115.58\n",
      "Epoch: 10 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.08 .. Rec_loss: 115.59 .. NELBO: 115.67\n",
      "Epoch: 10 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.08 .. Rec_loss: 115.51 .. NELBO: 115.59\n",
      "****************************************************************************************************\n",
      "Epoch----->10 .. LR: 0.005 .. KL_theta: 0.08 .. Rec_loss: 115.39 .. NELBO: 115.47\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 1005.1\n",
      "****************************************************************************************************\n",
      "####################################################################################################\n",
      "Visualize topics...\n",
      "Topic 0: ['great', 'work', 'good', 'time', 'easy', 'clean', 'product', 'nice', 'size']\n",
      "Topic 1: ['great', 'work', 'good', 'easy', 'time', 'clean', 'product', 'nice', 'size']\n",
      "Topic 2: ['great', 'work', 'good', 'easy', 'time', 'clean', 'product', 'nice', 'size']\n",
      "Topic 3: ['great', 'work', 'good', 'time', 'easy', 'clean', 'product', 'nice', 'size']\n",
      "Topic 4: ['great', 'work', 'good', 'time', 'easy', 'product', 'clean', 'nice', 'year']\n",
      "####################################################################################################\n",
      "Visualize word embeddings by using output embedding matrix\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: cleaner .. neighbors: ['cleaner', 'place', 'order', 'house', 'product', 'cover', 'wash', 'price', 'happy', 'unit', 'perfect', 'item', 'quality', 'hour', 'room', 'cook', 'wall', 'design', 'heat', 'fine']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: refrigerate .. neighbors: ['refrigerate', 'thesis', 'chuck', 'crop', 'dishpan', 'agent', 'knit', 'allot', 'sculpture', 'tarnish', 'lengthwise', 'cash', 'jumble', 'alcoholic', 'inevitable', 'teenage', 'broth', 'cutout', 'tempur', 'depress']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: tupperware .. neighbors: ['tupperware', 'sodastream', 'yank', 'dairy', 'guacamole', 'weighty', 'belief', 'impact', 'analog', 'vide', 'dipper', 'sauerkraut', 'additive', 'basil', 'cellar', 'brunch', 'forgive', 'tenderloin', 'accustom', 'parsley']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: curry .. neighbors: ['curry', 'grime', 'thesis', 'tempur', 'confusion', 'jumble', 'optimal', 'smudge', 'inaccurate', 'asparagus', 'ruffle', 'lithium', 'cruise', 'vaporizer', 'lengthwise', 'cutout', 'greek', 'martha', 'broth', 'alcoholic']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: baby .. neighbors: ['baby', 'show', 'hook', 'find', 'inch', 'touch', 'fact', 'start', 'fruit', 'hole', 'level', 'medium', 'hanger', 'boil', 'picture', 'read', 'cover', 'bite', 'bathroom', 'receive']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: weather .. neighbors: ['weather', 'puck', 'pear', 'partial', 'vide', 'poly', 'raspberry', 'culture', 'slap', 'allot', 'logo', 'consumption', 'attribute', 'skimpy', 'ticket', 'ditch', 'crunchy', 'centerpiece', 'cruise', 'cheerio']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: buffet .. neighbors: ['buffet', 'buzz', 'teenage', 'cutout', 'client', 'dance', 'boxy', 'lick', 'allot', 'couldnt', 'lengthwise', 'livingroom', 'sculpture', 'optimal', 'sneeze', 'endorse', 'martha', 'samsung', 'wrestle', 'tempur']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: ninja .. neighbors: ['ninja', 'thesis', 'perforation', 'vaporizer', 'wrestle', 'linger', 'jumble', 'bloody', 'sneeze', 'cruise', 'pedestal', 'canola', 'dishpan', 'broth', 'crucial', 'photography', 'barley', 'clearer', 'mexican', 'detect']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: fingernail .. neighbors: ['fingernail', 'buzz', 'jumble', 'sneeze', 'cruise', 'dance', 'lithium', 'thesis', 'lengthwise', 'grime', 'tempur', 'couldnt', 'cutout', 'boxy', 'depress', 'dishpan', 'perforation', 'livingroom', 'furnish', 'martha']\n",
      "####################################################################################################\n",
      "Epoch: 11 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.09 .. Rec_loss: 117.43 .. NELBO: 117.52\n",
      "Epoch: 11 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.09 .. Rec_loss: 115.57 .. NELBO: 115.66\n",
      "Epoch: 11 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.09 .. Rec_loss: 115.14 .. NELBO: 115.23\n",
      "Epoch: 11 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.09 .. Rec_loss: 115.33 .. NELBO: 115.42\n",
      "Epoch: 11 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.09 .. Rec_loss: 115.5 .. NELBO: 115.59\n",
      "Epoch: 11 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.09 .. Rec_loss: 115.4 .. NELBO: 115.49\n",
      "****************************************************************************************************\n",
      "Epoch----->11 .. LR: 0.005 .. KL_theta: 0.1 .. Rec_loss: 115.37 .. NELBO: 115.47\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 1002.7\n",
      "****************************************************************************************************\n",
      "Epoch: 12 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.1 .. Rec_loss: 115.06 .. NELBO: 115.16\n",
      "Epoch: 12 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.1 .. Rec_loss: 115.54 .. NELBO: 115.64\n",
      "Epoch: 12 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.11 .. Rec_loss: 116.02 .. NELBO: 116.13\n",
      "Epoch: 12 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.11 .. Rec_loss: 115.43 .. NELBO: 115.54\n",
      "Epoch: 12 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.11 .. Rec_loss: 115.2 .. NELBO: 115.31\n",
      "Epoch: 12 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.11 .. Rec_loss: 115.23 .. NELBO: 115.34\n",
      "****************************************************************************************************\n",
      "Epoch----->12 .. LR: 0.005 .. KL_theta: 0.11 .. Rec_loss: 115.38 .. NELBO: 115.49\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 1003.6\n",
      "****************************************************************************************************\n",
      "Epoch: 13 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.12 .. Rec_loss: 116.66 .. NELBO: 116.78\n",
      "Epoch: 13 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.12 .. Rec_loss: 115.05 .. NELBO: 115.17\n",
      "Epoch: 13 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.12 .. Rec_loss: 115.2 .. NELBO: 115.32\n",
      "Epoch: 13 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.12 .. Rec_loss: 115.05 .. NELBO: 115.17\n",
      "Epoch: 13 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.13 .. Rec_loss: 115.36 .. NELBO: 115.49\n",
      "Epoch: 13 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.13 .. Rec_loss: 115.3 .. NELBO: 115.43\n",
      "****************************************************************************************************\n",
      "Epoch----->13 .. LR: 0.005 .. KL_theta: 0.13 .. Rec_loss: 115.33 .. NELBO: 115.46\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 1002.2\n",
      "****************************************************************************************************\n",
      "Epoch: 14 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.14 .. Rec_loss: 116.97 .. NELBO: 117.11\n",
      "Epoch: 14 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.14 .. Rec_loss: 116.22 .. NELBO: 116.36\n",
      "Epoch: 14 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.15 .. Rec_loss: 115.81 .. NELBO: 115.96\n",
      "Epoch: 14 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.14 .. Rec_loss: 115.3 .. NELBO: 115.44\n",
      "Epoch: 14 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.14 .. Rec_loss: 115.15 .. NELBO: 115.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.14 .. Rec_loss: 115.28 .. NELBO: 115.42\n",
      "****************************************************************************************************\n",
      "Epoch----->14 .. LR: 0.005 .. KL_theta: 0.14 .. Rec_loss: 115.32 .. NELBO: 115.46\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 1004.0\n",
      "****************************************************************************************************\n",
      "Epoch: 15 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.17 .. Rec_loss: 116.3 .. NELBO: 116.47\n",
      "Epoch: 15 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.17 .. Rec_loss: 114.99 .. NELBO: 115.16\n",
      "Epoch: 15 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.16 .. Rec_loss: 114.91 .. NELBO: 115.07\n",
      "Epoch: 15 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.16 .. Rec_loss: 115.11 .. NELBO: 115.27\n",
      "Epoch: 15 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.16 .. Rec_loss: 114.75 .. NELBO: 114.91\n",
      "Epoch: 15 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.16 .. Rec_loss: 114.96 .. NELBO: 115.12\n",
      "****************************************************************************************************\n",
      "Epoch----->15 .. LR: 0.005 .. KL_theta: 0.16 .. Rec_loss: 115.32 .. NELBO: 115.48\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 1001.1\n",
      "****************************************************************************************************\n",
      "Epoch: 16 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.17 .. Rec_loss: 117.1 .. NELBO: 117.27\n",
      "Epoch: 16 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.19 .. Rec_loss: 116.92 .. NELBO: 117.11\n",
      "Epoch: 16 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.19 .. Rec_loss: 116.41 .. NELBO: 116.6\n",
      "Epoch: 16 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.18 .. Rec_loss: 116.08 .. NELBO: 116.26\n",
      "Epoch: 16 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.18 .. Rec_loss: 115.65 .. NELBO: 115.83\n",
      "Epoch: 16 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.18 .. Rec_loss: 115.25 .. NELBO: 115.43\n",
      "****************************************************************************************************\n",
      "Epoch----->16 .. LR: 0.005 .. KL_theta: 0.18 .. Rec_loss: 115.23 .. NELBO: 115.41\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 1001.8\n",
      "****************************************************************************************************\n",
      "Epoch: 17 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.21 .. Rec_loss: 114.94 .. NELBO: 115.15\n",
      "Epoch: 17 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.21 .. Rec_loss: 115.22 .. NELBO: 115.43\n",
      "Epoch: 17 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.2 .. Rec_loss: 116.2 .. NELBO: 116.4\n",
      "Epoch: 17 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.2 .. Rec_loss: 115.53 .. NELBO: 115.73\n",
      "Epoch: 17 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.21 .. Rec_loss: 115.52 .. NELBO: 115.73\n",
      "Epoch: 17 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.21 .. Rec_loss: 115.2 .. NELBO: 115.41\n",
      "****************************************************************************************************\n",
      "Epoch----->17 .. LR: 0.005 .. KL_theta: 0.21 .. Rec_loss: 115.16 .. NELBO: 115.37\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 998.9\n",
      "****************************************************************************************************\n",
      "Epoch: 18 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.24 .. Rec_loss: 113.91 .. NELBO: 114.15\n",
      "Epoch: 18 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.24 .. Rec_loss: 114.26 .. NELBO: 114.5\n",
      "Epoch: 18 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.24 .. Rec_loss: 114.59 .. NELBO: 114.83\n",
      "Epoch: 18 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.25 .. Rec_loss: 115.06 .. NELBO: 115.31\n",
      "Epoch: 18 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.26 .. Rec_loss: 115.51 .. NELBO: 115.77\n",
      "Epoch: 18 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.26 .. Rec_loss: 115.14 .. NELBO: 115.4\n",
      "****************************************************************************************************\n",
      "Epoch----->18 .. LR: 0.005 .. KL_theta: 0.26 .. Rec_loss: 115.07 .. NELBO: 115.33\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 997.0\n",
      "****************************************************************************************************\n",
      "Epoch: 19 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.34 .. Rec_loss: 116.1 .. NELBO: 116.44\n",
      "Epoch: 19 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.34 .. Rec_loss: 115.32 .. NELBO: 115.66\n",
      "Epoch: 19 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.32 .. Rec_loss: 115.67 .. NELBO: 115.99\n",
      "Epoch: 19 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.32 .. Rec_loss: 115.51 .. NELBO: 115.83\n",
      "Epoch: 19 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.33 .. Rec_loss: 115.29 .. NELBO: 115.62\n",
      "Epoch: 19 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.33 .. Rec_loss: 115.26 .. NELBO: 115.59\n",
      "****************************************************************************************************\n",
      "Epoch----->19 .. LR: 0.005 .. KL_theta: 0.33 .. Rec_loss: 114.89 .. NELBO: 115.22\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 992.0\n",
      "****************************************************************************************************\n",
      "Epoch: 20 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.37 .. Rec_loss: 115.24 .. NELBO: 115.61\n",
      "Epoch: 20 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.39 .. Rec_loss: 114.82 .. NELBO: 115.21\n",
      "Epoch: 20 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.38 .. Rec_loss: 114.66 .. NELBO: 115.04\n",
      "Epoch: 20 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.39 .. Rec_loss: 114.41 .. NELBO: 114.8\n",
      "Epoch: 20 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.39 .. Rec_loss: 114.68 .. NELBO: 115.07\n",
      "Epoch: 20 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.39 .. Rec_loss: 114.59 .. NELBO: 114.98\n",
      "****************************************************************************************************\n",
      "Epoch----->20 .. LR: 0.005 .. KL_theta: 0.4 .. Rec_loss: 114.76 .. NELBO: 115.16\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 988.1\n",
      "****************************************************************************************************\n",
      "####################################################################################################\n",
      "Visualize topics...\n",
      "Topic 0: ['work', 'great', 'good', 'time', 'product', 'nice', 'easy', 'thing', 'year']\n",
      "Topic 1: ['work', 'great', 'time', 'good', 'product', 'easy', 'thing', 'nice', 'year']\n",
      "Topic 2: ['coffee', 'great', 'easy', 'clean', 'good', 'water', 'size', 'work', 'filter']\n",
      "Topic 3: ['great', 'work', 'good', 'time', 'product', 'easy', 'nice', 'year', 'thing']\n",
      "Topic 4: ['mattress', 'work', 'thing', 'pillow', 'room', 'time', 'shower', 'product', 'white']\n",
      "####################################################################################################\n",
      "Visualize word embeddings by using output embedding matrix\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: cleaner .. neighbors: ['cleaner', 'product', 'price', 'order', 'item', 'wash', 'time', 'home', 'unit', 'nice', 'hand', 'small', 'heat', 'problem', 'great', 'work', 'size', 'worth', 'cheap', 'month']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: refrigerate .. neighbors: ['refrigerate', 'foolproof', 'registry', 'bialetti', 'bella', 'strike', 'slender', 'supplier', 'handful', 'unreliable', 'weaker', 'credit', 'enjoyment', 'bartender', 'roommate', 'dilute', 'strongest', 'fibrox', 'dishwater', 'remedy']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: tupperware .. neighbors: ['tupperware', 'impact', 'receptacle', 'decaf', 'weighty', 'concentrate', 'guacamole', 'patient', 'belief', 'prefect', 'budge', 'street', 'dairy', 'european', 'string', 'appetizer', 'puzzle', 'maneuverable', 'hooray', 'island']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: curry .. neighbors: ['curry', 'thesis', 'grime', 'confusion', 'asparagus', 'ruffle', 'lengthwise', 'jumble', 'martha', 'inaccurate', 'lithium', 'cruise', 'southern', 'livingroom', 'sneeze', 'tempur', 'buzz', 'muddle', 'sculpture', 'vaporizer']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: baby .. neighbors: ['baby', 'closet', 'fruit', 'inch', 'show', 'bathroom', 'head', 'mattress', 'dust', 'door', 'chair', 'start', 'soft', 'clothe', 'hook', 'hair', 'picture', 'cute', 'blender', 'hang']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: weather .. neighbors: ['weather', 'mite', 'dehydrator', 'dehydrate', 'unpack', 'sneaker', 'stress', 'controller', 'cucumber', 'gain', 'vide', 'lump', 'vanilla', 'halfway', 'analog', 'train', 'precise', 'thermostat', 'lasko', 'praise']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: buffet .. neighbors: ['buffet', 'samsung', 'livingroom', 'boxy', 'teenage', 'optimal', 'dishpan', 'execution', 'wrestle', 'sneeze', 'ghost', 'cash', 'martha', 'allot', 'gaudy', 'lick', 'boutique', 'guacamole', 'romaine', 'quote']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: ninja .. neighbors: ['ninja', 'evaluation', 'cruise', 'bloody', 'unacceptable', 'coin', 'tenderloin', 'leaky', 'ambient', 'fatigue', 'mouse', 'tolerance', 'southern', 'york', 'couldnt', 'dance', 'imho', 'rave', 'jumble', 'lobster']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: fingernail .. neighbors: ['fingernail', 'buzz', 'jumble', 'cruise', 'dance', 'lithium', 'lengthwise', 'sneeze', 'grime', 'couldnt', 'thesis', 'tempur', 'cutout', 'ruffle', 'tarnish', 'martha', 'imitation', 'imho', 'southern', 'boxy']\n",
      "####################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.49 .. Rec_loss: 116.0 .. NELBO: 116.49\n",
      "Epoch: 21 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.48 .. Rec_loss: 114.75 .. NELBO: 115.23\n",
      "Epoch: 21 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.48 .. Rec_loss: 114.25 .. NELBO: 114.73\n",
      "Epoch: 21 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.47 .. Rec_loss: 114.89 .. NELBO: 115.36\n",
      "Epoch: 21 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.47 .. Rec_loss: 115.04 .. NELBO: 115.51\n",
      "Epoch: 21 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.48 .. Rec_loss: 114.72 .. NELBO: 115.2\n",
      "****************************************************************************************************\n",
      "Epoch----->21 .. LR: 0.005 .. KL_theta: 0.49 .. Rec_loss: 114.53 .. NELBO: 115.02\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 978.1\n",
      "****************************************************************************************************\n",
      "Epoch: 22 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.56 .. Rec_loss: 113.5 .. NELBO: 114.06\n",
      "Epoch: 22 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.55 .. Rec_loss: 114.17 .. NELBO: 114.72\n",
      "Epoch: 22 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.56 .. Rec_loss: 114.65 .. NELBO: 115.21\n",
      "Epoch: 22 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.56 .. Rec_loss: 114.73 .. NELBO: 115.29\n",
      "Epoch: 22 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.56 .. Rec_loss: 114.11 .. NELBO: 114.67\n",
      "Epoch: 22 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.56 .. Rec_loss: 113.99 .. NELBO: 114.55\n",
      "****************************************************************************************************\n",
      "Epoch----->22 .. LR: 0.005 .. KL_theta: 0.56 .. Rec_loss: 114.37 .. NELBO: 114.93\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 971.2\n",
      "****************************************************************************************************\n",
      "Epoch: 23 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.56 .. Rec_loss: 113.25 .. NELBO: 113.81\n",
      "Epoch: 23 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.57 .. Rec_loss: 112.96 .. NELBO: 113.53\n",
      "Epoch: 23 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 114.06 .. NELBO: 114.65\n",
      "Epoch: 23 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.62 .. Rec_loss: 114.76 .. NELBO: 115.38\n",
      "Epoch: 23 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.63 .. Rec_loss: 114.57 .. NELBO: 115.2\n",
      "Epoch: 23 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.63 .. Rec_loss: 114.09 .. NELBO: 114.72\n",
      "****************************************************************************************************\n",
      "Epoch----->23 .. LR: 0.005 .. KL_theta: 0.63 .. Rec_loss: 114.17 .. NELBO: 114.8\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 965.9\n",
      "****************************************************************************************************\n",
      "Epoch: 24 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.74 .. Rec_loss: 113.8 .. NELBO: 114.54\n",
      "Epoch: 24 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.71 .. Rec_loss: 114.02 .. NELBO: 114.73\n",
      "Epoch: 24 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.69 .. Rec_loss: 113.67 .. NELBO: 114.36\n",
      "Epoch: 24 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.7 .. Rec_loss: 113.9 .. NELBO: 114.6\n",
      "Epoch: 24 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.72 .. Rec_loss: 113.87 .. NELBO: 114.59\n",
      "Epoch: 24 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.71 .. Rec_loss: 113.84 .. NELBO: 114.55\n",
      "****************************************************************************************************\n",
      "Epoch----->24 .. LR: 0.005 .. KL_theta: 0.7 .. Rec_loss: 114.01 .. NELBO: 114.71\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 959.8\n",
      "****************************************************************************************************\n",
      "Epoch: 25 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.78 .. Rec_loss: 113.83 .. NELBO: 114.61\n",
      "Epoch: 25 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.8 .. Rec_loss: 112.84 .. NELBO: 113.64\n",
      "Epoch: 25 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.75 .. Rec_loss: 113.2 .. NELBO: 113.95\n",
      "Epoch: 25 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.73 .. Rec_loss: 113.18 .. NELBO: 113.91\n",
      "Epoch: 25 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.74 .. Rec_loss: 113.29 .. NELBO: 114.03\n",
      "Epoch: 25 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.76 .. Rec_loss: 113.67 .. NELBO: 114.43\n",
      "****************************************************************************************************\n",
      "Epoch----->25 .. LR: 0.005 .. KL_theta: 0.76 .. Rec_loss: 113.83 .. NELBO: 114.59\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 952.7\n",
      "****************************************************************************************************\n",
      "Epoch: 26 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.73 .. Rec_loss: 115.55 .. NELBO: 116.28\n",
      "Epoch: 26 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.77 .. Rec_loss: 114.42 .. NELBO: 115.19\n",
      "Epoch: 26 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.78 .. Rec_loss: 113.97 .. NELBO: 114.75\n",
      "Epoch: 26 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.79 .. Rec_loss: 113.61 .. NELBO: 114.4\n",
      "Epoch: 26 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.78 .. Rec_loss: 113.53 .. NELBO: 114.31\n",
      "Epoch: 26 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.79 .. Rec_loss: 113.52 .. NELBO: 114.31\n",
      "****************************************************************************************************\n",
      "Epoch----->26 .. LR: 0.005 .. KL_theta: 0.8 .. Rec_loss: 113.7 .. NELBO: 114.5\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 946.7\n",
      "****************************************************************************************************\n",
      "Epoch: 27 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.88 .. Rec_loss: 114.43 .. NELBO: 115.31\n",
      "Epoch: 27 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.85 .. Rec_loss: 113.55 .. NELBO: 114.4\n",
      "Epoch: 27 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.84 .. Rec_loss: 113.43 .. NELBO: 114.27\n",
      "Epoch: 27 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.86 .. Rec_loss: 113.36 .. NELBO: 114.22\n",
      "Epoch: 27 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.87 .. Rec_loss: 113.0 .. NELBO: 113.87\n",
      "Epoch: 27 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.87 .. Rec_loss: 113.46 .. NELBO: 114.33\n",
      "****************************************************************************************************\n",
      "Epoch----->27 .. LR: 0.005 .. KL_theta: 0.87 .. Rec_loss: 113.54 .. NELBO: 114.41\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 943.9\n",
      "****************************************************************************************************\n",
      "Epoch: 28 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.9 .. Rec_loss: 112.31 .. NELBO: 113.21\n",
      "Epoch: 28 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.93 .. Rec_loss: 112.76 .. NELBO: 113.69\n",
      "Epoch: 28 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.91 .. Rec_loss: 113.08 .. NELBO: 113.99\n",
      "Epoch: 28 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.91 .. Rec_loss: 113.62 .. NELBO: 114.53\n",
      "Epoch: 28 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.91 .. Rec_loss: 113.47 .. NELBO: 114.38\n",
      "Epoch: 28 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.91 .. Rec_loss: 113.36 .. NELBO: 114.27\n",
      "****************************************************************************************************\n",
      "Epoch----->28 .. LR: 0.005 .. KL_theta: 0.91 .. Rec_loss: 113.43 .. NELBO: 114.34\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 936.8\n",
      "****************************************************************************************************\n",
      "Epoch: 29 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.99 .. Rec_loss: 114.66 .. NELBO: 115.65\n",
      "Epoch: 29 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.96 .. Rec_loss: 113.96 .. NELBO: 114.92\n",
      "Epoch: 29 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.94 .. Rec_loss: 114.31 .. NELBO: 115.25\n",
      "Epoch: 29 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.94 .. Rec_loss: 113.84 .. NELBO: 114.78\n",
      "Epoch: 29 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.94 .. Rec_loss: 113.63 .. NELBO: 114.57\n",
      "Epoch: 29 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.95 .. Rec_loss: 113.45 .. NELBO: 114.4\n",
      "****************************************************************************************************\n",
      "Epoch----->29 .. LR: 0.005 .. KL_theta: 0.95 .. Rec_loss: 113.28 .. NELBO: 114.23\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 932.2\n",
      "****************************************************************************************************\n",
      "Epoch: 30 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 0.93 .. Rec_loss: 114.52 .. NELBO: 115.45\n",
      "Epoch: 30 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 0.94 .. Rec_loss: 112.76 .. NELBO: 113.7\n",
      "Epoch: 30 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 0.93 .. Rec_loss: 112.65 .. NELBO: 113.58\n",
      "Epoch: 30 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 0.95 .. Rec_loss: 112.66 .. NELBO: 113.61\n",
      "Epoch: 30 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 0.96 .. Rec_loss: 113.14 .. NELBO: 114.1\n",
      "Epoch: 30 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 0.97 .. Rec_loss: 113.13 .. NELBO: 114.1\n",
      "****************************************************************************************************\n",
      "Epoch----->30 .. LR: 0.005 .. KL_theta: 0.97 .. Rec_loss: 113.21 .. NELBO: 114.18\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 929.7\n",
      "****************************************************************************************************\n",
      "####################################################################################################\n",
      "Visualize topics...\n",
      "Topic 0: ['great', 'work', 'good', 'easy', 'time', 'size', 'product', 'nice', 'price']\n",
      "Topic 1: ['great', 'work', 'easy', 'good', 'product', 'knife', 'time', 'clean', 'size']\n",
      "Topic 2: ['coffee', 'water', 'clean', 'work', 'great', 'easy', 'time', 'machine', 'filter']\n",
      "Topic 3: ['great', 'work', 'easy', 'good', 'product', 'knife', 'size', 'clean', 'time']\n",
      "Topic 4: ['vacuum', 'room', 'work', 'great', 'soft', 'good', 'pillow', 'time', 'mattress']\n",
      "####################################################################################################\n",
      "Visualize word embeddings by using output embedding matrix\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: cleaner .. neighbors: ['cleaner', 'pillow', 'loud', 'carpet', 'shower', 'battery', 'desk', 'night', 'dust', 'mattress', 'cord', 'noise', 'quiet', 'power', 'hair', 'odor', 'curtain', 'dirt', 'powerful', 'heater']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: refrigerate .. neighbors: ['refrigerate', 'foolproof', 'strike', 'multiclad', 'registry', 'swish', 'submerge', 'caramel', 'fancier', 'immerse', 'explode', 'cleave', 'aeropress', 'deni', 'puck', 'addict', 'canola', 'consume', 'marry', 'indian']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: tupperware .. neighbors: ['tupperware', 'protein', 'oval', 'soapy', 'kernel', 'colander', 'omelet', 'reheat', 'vinegar', 'soggy', 'smallest', 'prefer', 'cereal', 'foreman', 'chili', 'tasty', 'breakage', 'saucepan', 'breakfast', 'stockpot']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: curry .. neighbors: ['curry', 'optimal', 'lick', 'asparagus', 'dairy', 'mexican', 'broth', 'seafood', 'cash', 'dissipate', 'britta', 'thesis', 'discard', 'foolproof', 'overwhelm', 'dipper', 'theater', 'buffet', 'bormioli', 'deni']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: baby .. neighbors: ['baby', 'match', 'inch', 'picture', 'feel', 'color', 'towel', 'material', 'cover', 'arrive', 'thick', 'move', 'weight', 'assemble', 'wood', 'show', 'touch', 'cheap', 'return', 'pull']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: weather .. neighbors: ['weather', 'mite', 'lasko', 'silky', 'wake', 'broom', 'flannel', 'thermostat', 'surgery', 'sneaker', 'pinzon', 'sleeper', 'cozy', 'elastic', 'fluff', 'gain', 'massage', 'sweep', 'extension', 'firmness']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: buffet .. neighbors: ['buffet', 'registry', 'foolproof', 'optimal', 'discard', 'submerge', 'lick', 'seafood', 'cash', 'cater', 'bella', 'britta', 'bormioli', 'deni', 'dissipate', 'mexican', 'additive', 'dairy', 'luke', 'broth']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: ninja .. neighbors: ['ninja', 'perforation', 'livingroom', 'unhealthy', 'sculpture', 'swift', 'client', 'martha', 'guacamole', 'teenage', 'critter', 'stiffness', 'stow', 'beginner', 'cutest', 'grime', 'shovel', 'alcoholic', 'gaudy', 'detect']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: fingernail .. neighbors: ['fingernail', 'dishpan', 'thesis', 'lick', 'seafood', 'snapware', 'supervision', 'blanch', 'cheesecloth', 'lemonade', 'remedy', 'ghost', 'vast', 'briefly', 'canola', 'recall', 'mexican', 'insure', 'greek', 'alcoholic']\n",
      "####################################################################################################\n",
      "Epoch: 31 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.04 .. Rec_loss: 113.94 .. NELBO: 114.98\n",
      "Epoch: 31 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.05 .. Rec_loss: 112.55 .. NELBO: 113.6\n",
      "Epoch: 31 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.03 .. Rec_loss: 112.11 .. NELBO: 113.14\n",
      "Epoch: 31 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.04 .. Rec_loss: 112.82 .. NELBO: 113.86\n",
      "Epoch: 31 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.04 .. Rec_loss: 113.13 .. NELBO: 114.17\n",
      "Epoch: 31 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.05 .. Rec_loss: 113.17 .. NELBO: 114.22\n",
      "****************************************************************************************************\n",
      "Epoch----->31 .. LR: 0.005 .. KL_theta: 1.04 .. Rec_loss: 113.06 .. NELBO: 114.1\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 928.0\n",
      "****************************************************************************************************\n",
      "Epoch: 32 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.09 .. Rec_loss: 112.59 .. NELBO: 113.68\n",
      "Epoch: 32 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.11 .. Rec_loss: 112.59 .. NELBO: 113.7\n",
      "Epoch: 32 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.09 .. Rec_loss: 112.3 .. NELBO: 113.39\n",
      "Epoch: 32 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.08 .. Rec_loss: 112.62 .. NELBO: 113.7\n",
      "Epoch: 32 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.09 .. Rec_loss: 112.62 .. NELBO: 113.71\n",
      "Epoch: 32 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.09 .. Rec_loss: 112.72 .. NELBO: 113.81\n",
      "****************************************************************************************************\n",
      "Epoch----->32 .. LR: 0.005 .. KL_theta: 1.08 .. Rec_loss: 113.01 .. NELBO: 114.09\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 926.0\n",
      "****************************************************************************************************\n",
      "Epoch: 33 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.1 .. Rec_loss: 111.92 .. NELBO: 113.02\n",
      "Epoch: 33 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.14 .. Rec_loss: 112.05 .. NELBO: 113.19\n",
      "Epoch: 33 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.15 .. Rec_loss: 112.7 .. NELBO: 113.85\n",
      "Epoch: 33 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.14 .. Rec_loss: 112.62 .. NELBO: 113.76\n",
      "Epoch: 33 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.12 .. Rec_loss: 112.8 .. NELBO: 113.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.12 .. Rec_loss: 113.07 .. NELBO: 114.19\n",
      "****************************************************************************************************\n",
      "Epoch----->33 .. LR: 0.005 .. KL_theta: 1.13 .. Rec_loss: 112.91 .. NELBO: 114.04\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 923.7\n",
      "****************************************************************************************************\n",
      "Epoch: 34 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.26 .. Rec_loss: 112.8 .. NELBO: 114.06\n",
      "Epoch: 34 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.21 .. Rec_loss: 112.67 .. NELBO: 113.88\n",
      "Epoch: 34 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.17 .. Rec_loss: 113.18 .. NELBO: 114.35\n",
      "Epoch: 34 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.17 .. Rec_loss: 112.42 .. NELBO: 113.59\n",
      "Epoch: 34 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.18 .. Rec_loss: 113.2 .. NELBO: 114.38\n",
      "Epoch: 34 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.18 .. Rec_loss: 112.76 .. NELBO: 113.94\n",
      "****************************************************************************************************\n",
      "Epoch----->34 .. LR: 0.005 .. KL_theta: 1.18 .. Rec_loss: 112.85 .. NELBO: 114.03\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 923.4\n",
      "****************************************************************************************************\n",
      "Epoch: 35 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.08 .. Rec_loss: 112.27 .. NELBO: 113.35\n",
      "Epoch: 35 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.13 .. Rec_loss: 112.26 .. NELBO: 113.39\n",
      "Epoch: 35 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.17 .. Rec_loss: 112.66 .. NELBO: 113.83\n",
      "Epoch: 35 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.18 .. Rec_loss: 113.11 .. NELBO: 114.29\n",
      "Epoch: 35 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.18 .. Rec_loss: 113.44 .. NELBO: 114.62\n",
      "Epoch: 35 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.17 .. Rec_loss: 112.9 .. NELBO: 114.07\n",
      "****************************************************************************************************\n",
      "Epoch----->35 .. LR: 0.005 .. KL_theta: 1.17 .. Rec_loss: 112.74 .. NELBO: 113.91\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 918.9\n",
      "****************************************************************************************************\n",
      "Epoch: 36 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.25 .. Rec_loss: 113.42 .. NELBO: 114.67\n",
      "Epoch: 36 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.25 .. Rec_loss: 112.68 .. NELBO: 113.93\n",
      "Epoch: 36 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.23 .. Rec_loss: 112.73 .. NELBO: 113.96\n",
      "Epoch: 36 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.23 .. Rec_loss: 112.91 .. NELBO: 114.14\n",
      "Epoch: 36 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.24 .. Rec_loss: 112.97 .. NELBO: 114.21\n",
      "Epoch: 36 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.23 .. Rec_loss: 112.5 .. NELBO: 113.73\n",
      "****************************************************************************************************\n",
      "Epoch----->36 .. LR: 0.005 .. KL_theta: 1.22 .. Rec_loss: 112.66 .. NELBO: 113.88\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 919.7\n",
      "****************************************************************************************************\n",
      "Epoch: 37 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.22 .. Rec_loss: 115.27 .. NELBO: 116.49\n",
      "Epoch: 37 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.23 .. Rec_loss: 114.26 .. NELBO: 115.49\n",
      "Epoch: 37 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.25 .. Rec_loss: 113.26 .. NELBO: 114.51\n",
      "Epoch: 37 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.24 .. Rec_loss: 112.49 .. NELBO: 113.73\n",
      "Epoch: 37 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.23 .. Rec_loss: 112.59 .. NELBO: 113.82\n",
      "Epoch: 37 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.23 .. Rec_loss: 112.56 .. NELBO: 113.79\n",
      "****************************************************************************************************\n",
      "Epoch----->37 .. LR: 0.005 .. KL_theta: 1.23 .. Rec_loss: 112.62 .. NELBO: 113.85\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 915.4\n",
      "****************************************************************************************************\n",
      "Epoch: 38 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.31 .. Rec_loss: 112.97 .. NELBO: 114.28\n",
      "Epoch: 38 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.28 .. Rec_loss: 113.11 .. NELBO: 114.39\n",
      "Epoch: 38 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.25 .. Rec_loss: 113.03 .. NELBO: 114.28\n",
      "Epoch: 38 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.26 .. Rec_loss: 112.6 .. NELBO: 113.86\n",
      "Epoch: 38 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.26 .. Rec_loss: 112.29 .. NELBO: 113.55\n",
      "Epoch: 38 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.27 .. Rec_loss: 112.46 .. NELBO: 113.73\n",
      "****************************************************************************************************\n",
      "Epoch----->38 .. LR: 0.005 .. KL_theta: 1.26 .. Rec_loss: 112.52 .. NELBO: 113.78\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 914.6\n",
      "****************************************************************************************************\n",
      "Epoch: 39 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.23 .. Rec_loss: 113.13 .. NELBO: 114.36\n",
      "Epoch: 39 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.26 .. Rec_loss: 113.29 .. NELBO: 114.55\n",
      "Epoch: 39 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.28 .. Rec_loss: 112.94 .. NELBO: 114.22\n",
      "Epoch: 39 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.29 .. Rec_loss: 112.82 .. NELBO: 114.11\n",
      "Epoch: 39 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.29 .. Rec_loss: 112.5 .. NELBO: 113.79\n",
      "Epoch: 39 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.28 .. Rec_loss: 112.48 .. NELBO: 113.76\n",
      "****************************************************************************************************\n",
      "Epoch----->39 .. LR: 0.005 .. KL_theta: 1.28 .. Rec_loss: 112.45 .. NELBO: 113.73\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 913.5\n",
      "****************************************************************************************************\n",
      "Epoch: 40 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.33 .. Rec_loss: 112.72 .. NELBO: 114.05\n",
      "Epoch: 40 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.3 .. Rec_loss: 111.25 .. NELBO: 112.55\n",
      "Epoch: 40 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.31 .. Rec_loss: 111.38 .. NELBO: 112.69\n",
      "Epoch: 40 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.3 .. Rec_loss: 112.27 .. NELBO: 113.57\n",
      "Epoch: 40 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.3 .. Rec_loss: 112.09 .. NELBO: 113.39\n",
      "Epoch: 40 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.3 .. Rec_loss: 112.48 .. NELBO: 113.78\n",
      "****************************************************************************************************\n",
      "Epoch----->40 .. LR: 0.005 .. KL_theta: 1.31 .. Rec_loss: 112.37 .. NELBO: 113.68\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 910.9\n",
      "****************************************************************************************************\n",
      "####################################################################################################\n",
      "Visualize topics...\n",
      "Topic 0: ['great', 'price', 'product', 'good', 'quality', 'purchase', 'size', 'nice', 'easy']\n",
      "Topic 1: ['great', 'work', 'good', 'easy', 'time', 'product', 'size', 'clean', 'nice']\n",
      "Topic 2: ['coffee', 'water', 'work', 'clean', 'time', 'easy', 'machine', 'great', 'filter']\n",
      "Topic 3: ['cook', 'food', 'knife', 'clean', 'stick', 'easy', 'bowl', 'work', 'bread']\n",
      "Topic 4: ['vacuum', 'room', 'floor', 'work', 'pillow', 'great', 'sheet', 'soft', 'time']\n",
      "####################################################################################################\n",
      "Visualize word embeddings by using output embedding matrix\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: cleaner .. neighbors: ['cleaner', 'cord', 'loud', 'night', 'desk', 'odor', 'pillow', 'dust', 'noise', 'spring', 'shower', 'quiet', 'body', 'powerful', 'carpet', 'battery', 'power', 'heater', 'vacuum', 'floor']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: refrigerate .. neighbors: ['refrigerate', 'menu', 'thaw', 'swish', 'strike', 'puck', 'caramel', 'deni', 'dishwater', 'grandchild', 'november', 'bold', 'registry', 'briefly', 'yeast', 'addict', 'tonight', 'lifestyle', 'bormioli', 'flavorful']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: tupperware .. neighbors: ['tupperware', 'colander', 'soapy', 'cereal', 'omelet', 'saucepan', 'snack', 'prep', 'mason', 'smallest', 'coconut', 'breville', 'crispy', 'ladle', 'calorie', 'lifetime', 'oval', 'dessert', 'noodle', 'spaghetti']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: curry .. neighbors: ['curry', 'lick', 'fingernail', 'leach', 'mexican', 'rosemary', 'seafood', 'sculpture', 'hash', 'snapware', 'buffet', 'multiclad', 'vast', 'edible', 'stumble', 'mayonnaise', 'import', 'slender', 'tail', 'toxin']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: baby .. neighbors: ['baby', 'head', 'cover', 'pull', 'touch', 'white', 'rest', 'wear', 'deep', 'move', 'pain', 'pick', 'flat', 'feel', 'side', 'degree', 'spot', 'short', 'entire', 'comfortable']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: weather .. neighbors: ['weather', 'wake', 'cozy', 'flannel', 'sleeper', 'roomba', 'fluff', 'twin', 'warmth', 'skirt', 'thermostat', 'silky', 'knee', 'mite', 'elastic', 'allergy', 'extension', 'loft', 'lasko', 'pant']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: buffet .. neighbors: ['buffet', 'lemonade', 'seafood', 'snapware', 'addict', 'lick', 'street', 'rosemary', 'cater', 'deni', 'thaw', 'toxin', 'submerge', 'canola', 'stumble', 'fillet', 'leach', 'registry', 'secret', 'mood']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: ninja .. neighbors: ['ninja', 'canola', 'unhealthy', 'leech', 'alcoholic', 'greek', 'seafood', 'tail', 'unacceptable', 'sculpture', 'dishpan', 'snapware', 'edible', 'classier', 'leach', 'vast', 'thesis', 'physical', 'lick', 'mexican']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: fingernail .. neighbors: ['fingernail', 'lick', 'mexican', 'blanch', 'supervision', 'mayonnaise', 'seafood', 'sculpture', 'vast', 'crusher', 'hash', 'leach', 'import', 'straighten', 'rosemary', 'pusher', 'beginner', 'discontinue', 'critter', 'curry']\n",
      "####################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.36 .. Rec_loss: 112.96 .. NELBO: 114.32\n",
      "Epoch: 41 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.36 .. Rec_loss: 113.32 .. NELBO: 114.68\n",
      "Epoch: 41 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.36 .. Rec_loss: 113.06 .. NELBO: 114.42\n",
      "Epoch: 41 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.35 .. Rec_loss: 112.96 .. NELBO: 114.31\n",
      "Epoch: 41 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.35 .. Rec_loss: 112.67 .. NELBO: 114.02\n",
      "Epoch: 41 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.35 .. Rec_loss: 112.39 .. NELBO: 113.74\n",
      "****************************************************************************************************\n",
      "Epoch----->41 .. LR: 0.005 .. KL_theta: 1.35 .. Rec_loss: 112.32 .. NELBO: 113.67\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 909.5\n",
      "****************************************************************************************************\n",
      "Epoch: 42 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.32 .. Rec_loss: 112.09 .. NELBO: 113.41\n",
      "Epoch: 42 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.33 .. Rec_loss: 111.57 .. NELBO: 112.9\n",
      "Epoch: 42 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.33 .. Rec_loss: 112.03 .. NELBO: 113.36\n",
      "Epoch: 42 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.34 .. Rec_loss: 112.44 .. NELBO: 113.78\n",
      "Epoch: 42 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.34 .. Rec_loss: 112.46 .. NELBO: 113.8\n",
      "Epoch: 42 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.36 .. Rec_loss: 112.54 .. NELBO: 113.9\n",
      "****************************************************************************************************\n",
      "Epoch----->42 .. LR: 0.005 .. KL_theta: 1.36 .. Rec_loss: 112.24 .. NELBO: 113.6\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 908.7\n",
      "****************************************************************************************************\n",
      "Epoch: 43 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.43 .. Rec_loss: 113.24 .. NELBO: 114.67\n",
      "Epoch: 43 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.42 .. Rec_loss: 112.63 .. NELBO: 114.05\n",
      "Epoch: 43 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.4 .. Rec_loss: 112.68 .. NELBO: 114.08\n",
      "Epoch: 43 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.4 .. Rec_loss: 112.74 .. NELBO: 114.14\n",
      "Epoch: 43 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.4 .. Rec_loss: 112.35 .. NELBO: 113.75\n",
      "Epoch: 43 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.39 .. Rec_loss: 112.17 .. NELBO: 113.56\n",
      "****************************************************************************************************\n",
      "Epoch----->43 .. LR: 0.005 .. KL_theta: 1.39 .. Rec_loss: 112.19 .. NELBO: 113.58\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 905.4\n",
      "****************************************************************************************************\n",
      "Epoch: 44 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.39 .. Rec_loss: 110.81 .. NELBO: 112.2\n",
      "Epoch: 44 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.43 .. Rec_loss: 111.88 .. NELBO: 113.31\n",
      "Epoch: 44 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.43 .. Rec_loss: 112.16 .. NELBO: 113.59\n",
      "Epoch: 44 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.42 .. Rec_loss: 112.31 .. NELBO: 113.73\n",
      "Epoch: 44 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.41 .. Rec_loss: 112.05 .. NELBO: 113.46\n",
      "Epoch: 44 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.41 .. Rec_loss: 112.13 .. NELBO: 113.54\n",
      "****************************************************************************************************\n",
      "Epoch----->44 .. LR: 0.005 .. KL_theta: 1.41 .. Rec_loss: 112.14 .. NELBO: 113.55\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 904.4\n",
      "****************************************************************************************************\n",
      "Epoch: 45 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.48 .. Rec_loss: 110.93 .. NELBO: 112.41\n",
      "Epoch: 45 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.49 .. Rec_loss: 111.77 .. NELBO: 113.26\n",
      "Epoch: 45 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.46 .. Rec_loss: 111.66 .. NELBO: 113.12\n",
      "Epoch: 45 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.45 .. Rec_loss: 111.87 .. NELBO: 113.32\n",
      "Epoch: 45 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.45 .. Rec_loss: 112.07 .. NELBO: 113.52\n",
      "Epoch: 45 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.44 .. Rec_loss: 112.11 .. NELBO: 113.55\n",
      "****************************************************************************************************\n",
      "Epoch----->45 .. LR: 0.005 .. KL_theta: 1.44 .. Rec_loss: 112.08 .. NELBO: 113.52\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 903.1\n",
      "****************************************************************************************************\n",
      "Epoch: 46 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.46 .. Rec_loss: 112.48 .. NELBO: 113.94\n",
      "Epoch: 46 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.47 .. Rec_loss: 111.5 .. NELBO: 112.97\n",
      "Epoch: 46 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.46 .. Rec_loss: 111.33 .. NELBO: 112.79\n",
      "Epoch: 46 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.46 .. Rec_loss: 112.1 .. NELBO: 113.56\n",
      "Epoch: 46 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.46 .. Rec_loss: 111.98 .. NELBO: 113.44\n",
      "Epoch: 46 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.47 .. Rec_loss: 112.28 .. NELBO: 113.75\n",
      "****************************************************************************************************\n",
      "Epoch----->46 .. LR: 0.005 .. KL_theta: 1.47 .. Rec_loss: 112.0 .. NELBO: 113.47\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 903.3\n",
      "****************************************************************************************************\n",
      "Epoch: 47 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.49 .. Rec_loss: 112.8 .. NELBO: 114.29\n",
      "Epoch: 47 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.5 .. Rec_loss: 111.61 .. NELBO: 113.11\n",
      "Epoch: 47 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.48 .. Rec_loss: 111.5 .. NELBO: 112.98\n",
      "Epoch: 47 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.46 .. Rec_loss: 111.49 .. NELBO: 112.95\n",
      "Epoch: 47 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.48 .. Rec_loss: 111.69 .. NELBO: 113.17\n",
      "Epoch: 47 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.5 .. Rec_loss: 112.05 .. NELBO: 113.55\n",
      "****************************************************************************************************\n",
      "Epoch----->47 .. LR: 0.005 .. KL_theta: 1.51 .. Rec_loss: 111.94 .. NELBO: 113.45\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 902.6\n",
      "****************************************************************************************************\n",
      "Epoch: 48 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.4 .. Rec_loss: 113.13 .. NELBO: 114.53\n",
      "Epoch: 48 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.41 .. Rec_loss: 112.67 .. NELBO: 114.08\n",
      "Epoch: 48 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.48 .. Rec_loss: 112.35 .. NELBO: 113.83\n",
      "Epoch: 48 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.5 .. Rec_loss: 111.69 .. NELBO: 113.19\n",
      "Epoch: 48 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.5 .. Rec_loss: 111.8 .. NELBO: 113.3\n",
      "Epoch: 48 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.49 .. Rec_loss: 111.83 .. NELBO: 113.32\n",
      "****************************************************************************************************\n",
      "Epoch----->48 .. LR: 0.005 .. KL_theta: 1.49 .. Rec_loss: 111.95 .. NELBO: 113.44\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 900.2\n",
      "****************************************************************************************************\n",
      "Epoch: 49 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.55 .. Rec_loss: 112.37 .. NELBO: 113.92\n",
      "Epoch: 49 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.53 .. Rec_loss: 110.63 .. NELBO: 112.16\n",
      "Epoch: 49 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.53 .. Rec_loss: 111.3 .. NELBO: 112.83\n",
      "Epoch: 49 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.52 .. Rec_loss: 111.48 .. NELBO: 113.0\n",
      "Epoch: 49 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.52 .. Rec_loss: 111.71 .. NELBO: 113.23\n",
      "Epoch: 49 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.53 .. Rec_loss: 112.01 .. NELBO: 113.54\n",
      "****************************************************************************************************\n",
      "Epoch----->49 .. LR: 0.005 .. KL_theta: 1.53 .. Rec_loss: 111.84 .. NELBO: 113.37\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 899.1\n",
      "****************************************************************************************************\n",
      "Epoch: 50 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.5 .. Rec_loss: 111.92 .. NELBO: 113.42\n",
      "Epoch: 50 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.5 .. Rec_loss: 112.0 .. NELBO: 113.5\n",
      "Epoch: 50 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.5 .. Rec_loss: 112.1 .. NELBO: 113.6\n",
      "Epoch: 50 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.53 .. Rec_loss: 111.86 .. NELBO: 113.39\n",
      "Epoch: 50 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.54 .. Rec_loss: 111.82 .. NELBO: 113.36\n",
      "Epoch: 50 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.54 .. Rec_loss: 111.91 .. NELBO: 113.45\n",
      "****************************************************************************************************\n",
      "Epoch----->50 .. LR: 0.005 .. KL_theta: 1.54 .. Rec_loss: 111.83 .. NELBO: 113.37\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 900.5\n",
      "****************************************************************************************************\n",
      "####################################################################################################\n",
      "Visualize topics...\n",
      "Topic 0: ['nice', 'price', 'color', 'quality', 'good', 'item', 'order', 'sturdy', 'purchase']\n",
      "Topic 1: ['great', 'work', 'good', 'easy', 'size', 'product', 'time', 'clean', 'nice']\n",
      "Topic 2: ['coffee', 'water', 'work', 'filter', 'time', 'machine', 'great', 'clean', 'grind']\n",
      "Topic 3: ['cook', 'stick', 'food', 'clean', 'great', 'knife', 'work', 'easy', 'time']\n",
      "Topic 4: ['vacuum', 'work', 'great', 'room', 'floor', 'sheet', 'time', 'pillow', 'soft']\n",
      "####################################################################################################\n",
      "Visualize word embeddings by using output embedding matrix\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: cleaner .. neighbors: ['cleaner', 'odor', 'cord', 'noise', 'dust', 'quiet', 'night', 'loud', 'spring', 'foam', 'battery', 'heater', 'pillow', 'carpet', 'powerful', 'shower', 'mattress', 'vacuum', 'washable', 'curtain']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: refrigerate .. neighbors: ['refrigerate', 'menu', 'stumble', 'famous', 'puck', 'flavorful', 'goody', 'squirt', 'pulse', 'yeast', 'lifestyle', 'reserve', 'explode', 'swish', 'bind', 'bold', 'variation', 'addict', 'tonight', 'immerse']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: tupperware .. neighbors: ['tupperware', 'pyrex', 'strain', 'cereal', 'mason', 'leftover', 'cork', 'occasion', 'reusable', 'mitt', 'clumsy', 'snack', 'regard', 'quantity', 'dessert', 'bulk', 'inside', 'silverware', 'smallest', 'cookbook']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: curry .. neighbors: ['curry', 'multiclad', 'fingertip', 'apprehensive', 'fingernail', 'beginner', 'mayonnaise', 'mexican', 'lick', 'blueberry', 'equip', 'jiffy', 'hummus', 'sculpture', 'eater', 'straighten', 'hash', 'buffet', 'fibrox', 'blanch']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: baby .. neighbors: ['baby', 'short', 'head', 'pain', 'pick', 'watch', 'older', 'push', 'pull', 'entire', 'turn', 'degree', 'heat', 'model', 'awesome', 'test', 'start', 'life', 'hate', 'control']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: weather .. neighbors: ['weather', 'wake', 'fluff', 'humidifier', 'warmth', 'thermostat', 'loft', 'twin', 'sleeper', 'knee', 'roomba', 'extension', 'lady', 'eureka', 'flannel', 'cozy', 'pant', 'mite', 'furnace', 'honeywell']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: buffet .. neighbors: ['buffet', 'lick', 'seafood', 'sculpture', 'lemonade', 'pusher', 'hash', 'briefly', 'tail', 'fingernail', 'shave', 'remainder', 'deni', 'thaw', 'trader', 'cater', 'cauliflower', 'street', 'equip', 'chewy']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: ninja .. neighbors: ['ninja', 'thaw', 'fillet', 'unhealthy', 'tail', 'cauliflower', 'puck', 'canola', 'deni', 'lemonade', 'chewy', 'cater', 'street', 'trader', 'mood', 'acid', 'amco', 'deserve', 'nutrient', 'seafood']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: fingernail .. neighbors: ['fingernail', 'equip', 'sculpture', 'hash', 'mayonnaise', 'fountain', 'mexican', 'seafood', 'hummus', 'blueberry', 'fingertip', 'blanch', 'lick', 'supervision', 'beginner', 'buffet', 'radish', 'tail', 'fibrox', 'multiclad']\n",
      "####################################################################################################\n",
      "Epoch: 51 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.56 .. Rec_loss: 112.76 .. NELBO: 114.32\n",
      "Epoch: 51 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.58 .. Rec_loss: 112.33 .. NELBO: 113.91\n",
      "Epoch: 51 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.59 .. Rec_loss: 112.41 .. NELBO: 114.0\n",
      "Epoch: 51 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.56 .. Rec_loss: 112.2 .. NELBO: 113.76\n",
      "Epoch: 51 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.55 .. Rec_loss: 111.92 .. NELBO: 113.47\n",
      "Epoch: 51 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.55 .. Rec_loss: 111.9 .. NELBO: 113.45\n",
      "****************************************************************************************************\n",
      "Epoch----->51 .. LR: 0.005 .. KL_theta: 1.56 .. Rec_loss: 111.77 .. NELBO: 113.33\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 899.0\n",
      "****************************************************************************************************\n",
      "Epoch: 52 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 113.42 .. NELBO: 115.08\n",
      "Epoch: 52 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.65 .. Rec_loss: 112.75 .. NELBO: 114.4\n",
      "Epoch: 52 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.62 .. Rec_loss: 112.47 .. NELBO: 114.09\n",
      "Epoch: 52 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.59 .. Rec_loss: 112.08 .. NELBO: 113.67\n",
      "Epoch: 52 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.57 .. Rec_loss: 111.71 .. NELBO: 113.28\n",
      "Epoch: 52 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.58 .. Rec_loss: 111.65 .. NELBO: 113.23\n",
      "****************************************************************************************************\n",
      "Epoch----->52 .. LR: 0.005 .. KL_theta: 1.59 .. Rec_loss: 111.77 .. NELBO: 113.36\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 897.1\n",
      "****************************************************************************************************\n",
      "Epoch: 53 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 113.16 .. NELBO: 114.83\n",
      "Epoch: 53 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.64 .. Rec_loss: 112.68 .. NELBO: 114.32\n",
      "Epoch: 53 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.62 .. Rec_loss: 112.0 .. NELBO: 113.62\n",
      "Epoch: 53 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.62 .. Rec_loss: 112.19 .. NELBO: 113.81\n",
      "Epoch: 53 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.61 .. Rec_loss: 112.26 .. NELBO: 113.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.61 .. Rec_loss: 112.04 .. NELBO: 113.65\n",
      "****************************************************************************************************\n",
      "Epoch----->53 .. LR: 0.005 .. KL_theta: 1.6 .. Rec_loss: 111.65 .. NELBO: 113.25\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 895.8\n",
      "****************************************************************************************************\n",
      "Epoch: 54 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.63 .. Rec_loss: 113.12 .. NELBO: 114.75\n",
      "Epoch: 54 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.6 .. Rec_loss: 113.1 .. NELBO: 114.7\n",
      "Epoch: 54 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.59 .. Rec_loss: 113.29 .. NELBO: 114.88\n",
      "Epoch: 54 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.6 .. Rec_loss: 112.36 .. NELBO: 113.96\n",
      "Epoch: 54 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.59 .. Rec_loss: 111.57 .. NELBO: 113.16\n",
      "Epoch: 54 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.59 .. Rec_loss: 111.68 .. NELBO: 113.27\n",
      "****************************************************************************************************\n",
      "Epoch----->54 .. LR: 0.005 .. KL_theta: 1.58 .. Rec_loss: 111.65 .. NELBO: 113.23\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 895.7\n",
      "****************************************************************************************************\n",
      "Epoch: 55 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.56 .. Rec_loss: 110.93 .. NELBO: 112.49\n",
      "Epoch: 55 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.59 .. Rec_loss: 111.74 .. NELBO: 113.33\n",
      "Epoch: 55 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.61 .. Rec_loss: 111.57 .. NELBO: 113.18\n",
      "Epoch: 55 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.63 .. Rec_loss: 112.4 .. NELBO: 114.03\n",
      "Epoch: 55 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.62 .. Rec_loss: 112.15 .. NELBO: 113.77\n",
      "Epoch: 55 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.6 .. Rec_loss: 111.92 .. NELBO: 113.52\n",
      "****************************************************************************************************\n",
      "Epoch----->55 .. LR: 0.005 .. KL_theta: 1.6 .. Rec_loss: 111.62 .. NELBO: 113.22\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 894.0\n",
      "****************************************************************************************************\n",
      "Epoch: 56 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.69 .. Rec_loss: 111.64 .. NELBO: 113.33\n",
      "Epoch: 56 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 111.67 .. NELBO: 113.34\n",
      "Epoch: 56 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.64 .. Rec_loss: 110.97 .. NELBO: 112.61\n",
      "Epoch: 56 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.63 .. Rec_loss: 111.34 .. NELBO: 112.97\n",
      "Epoch: 56 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.64 .. Rec_loss: 111.53 .. NELBO: 113.17\n",
      "Epoch: 56 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.64 .. Rec_loss: 111.7 .. NELBO: 113.34\n",
      "****************************************************************************************************\n",
      "Epoch----->56 .. LR: 0.005 .. KL_theta: 1.65 .. Rec_loss: 111.57 .. NELBO: 113.22\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 895.3\n",
      "****************************************************************************************************\n",
      "Epoch: 57 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.59 .. Rec_loss: 110.48 .. NELBO: 112.07\n",
      "Epoch: 57 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.58 .. Rec_loss: 111.28 .. NELBO: 112.86\n",
      "Epoch: 57 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.6 .. Rec_loss: 111.36 .. NELBO: 112.96\n",
      "Epoch: 57 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.62 .. Rec_loss: 111.56 .. NELBO: 113.18\n",
      "Epoch: 57 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.64 .. Rec_loss: 112.0 .. NELBO: 113.64\n",
      "Epoch: 57 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.63 .. Rec_loss: 111.82 .. NELBO: 113.45\n",
      "****************************************************************************************************\n",
      "Epoch----->57 .. LR: 0.005 .. KL_theta: 1.63 .. Rec_loss: 111.56 .. NELBO: 113.19\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 892.2\n",
      "****************************************************************************************************\n",
      "Epoch: 58 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.64 .. Rec_loss: 112.32 .. NELBO: 113.96\n",
      "Epoch: 58 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 111.78 .. NELBO: 113.44\n",
      "Epoch: 58 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 111.4 .. NELBO: 113.06\n",
      "Epoch: 58 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.65 .. Rec_loss: 111.36 .. NELBO: 113.01\n",
      "Epoch: 58 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.64 .. Rec_loss: 111.58 .. NELBO: 113.22\n",
      "Epoch: 58 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.64 .. Rec_loss: 111.53 .. NELBO: 113.17\n",
      "****************************************************************************************************\n",
      "Epoch----->58 .. LR: 0.005 .. KL_theta: 1.64 .. Rec_loss: 111.54 .. NELBO: 113.18\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 893.9\n",
      "****************************************************************************************************\n",
      "Epoch: 59 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.7 .. Rec_loss: 113.22 .. NELBO: 114.92\n",
      "Epoch: 59 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 112.89 .. NELBO: 114.56\n",
      "Epoch: 59 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.65 .. Rec_loss: 112.63 .. NELBO: 114.28\n",
      "Epoch: 59 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.63 .. Rec_loss: 112.35 .. NELBO: 113.98\n",
      "Epoch: 59 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.64 .. Rec_loss: 112.11 .. NELBO: 113.75\n",
      "Epoch: 59 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.64 .. Rec_loss: 111.72 .. NELBO: 113.36\n",
      "****************************************************************************************************\n",
      "Epoch----->59 .. LR: 0.005 .. KL_theta: 1.65 .. Rec_loss: 111.5 .. NELBO: 113.15\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 890.8\n",
      "****************************************************************************************************\n",
      "Epoch: 60 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.63 .. Rec_loss: 110.68 .. NELBO: 112.31\n",
      "Epoch: 60 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.63 .. Rec_loss: 110.49 .. NELBO: 112.12\n",
      "Epoch: 60 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.62 .. Rec_loss: 110.64 .. NELBO: 112.26\n",
      "Epoch: 60 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.63 .. Rec_loss: 110.86 .. NELBO: 112.49\n",
      "Epoch: 60 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.63 .. Rec_loss: 111.31 .. NELBO: 112.94\n",
      "Epoch: 60 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.64 .. Rec_loss: 111.6 .. NELBO: 113.24\n",
      "****************************************************************************************************\n",
      "Epoch----->60 .. LR: 0.005 .. KL_theta: 1.64 .. Rec_loss: 111.48 .. NELBO: 113.12\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 889.2\n",
      "****************************************************************************************************\n",
      "####################################################################################################\n",
      "Visualize topics...\n",
      "Topic 0: ['color', 'price', 'nice', 'good', 'great', 'item', 'product', 'order', 'sturdy']\n",
      "Topic 1: ['great', 'size', 'work', 'good', 'product', 'easy', 'nice', 'plastic', 'time']\n",
      "Topic 2: ['coffee', 'water', 'work', 'time', 'great', 'easy', 'clean', 'machine', 'filter']\n",
      "Topic 3: ['cook', 'clean', 'great', 'knife', 'easy', 'stick', 'work', 'time', 'good']\n",
      "Topic 4: ['work', 'great', 'vacuum', 'good', 'time', 'pillow', 'room', 'sheet', 'clean']\n",
      "####################################################################################################\n",
      "Visualize word embeddings by using output embedding matrix\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: cleaner .. neighbors: ['cleaner', 'noise', 'odor', 'quiet', 'dust', 'foam', 'carpet', 'heater', 'battery', 'pillow', 'cord', 'dirt', 'mattress', 'sleep', 'curtain', 'night', 'loud', 'vacuum', 'spring', 'powerful']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: refrigerate .. neighbors: ['refrigerate', 'lifestyle', 'marry', 'explode', 'sift', 'tonight', 'november', 'cleanser', 'alton', 'bind', 'metric', 'intention', 'snapware', 'acid', 'tbsp', 'pace', 'microwavable', 'rocket', 'dislodge', 'street']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: tupperware .. neighbors: ['tupperware', 'mason', 'popsicle', 'sealer', 'pyrex', 'chiller', 'appetizer', 'cork', 'pourer', 'bento', 'rubbermaid', 'conversation', 'leftover', 'cereal', 'strain', 'stemless', 'corkscrew', 'costly', 'indestructible', 'champagne']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: curry .. neighbors: ['curry', 'edible', 'lick', 'eater', 'leach', 'fondue', 'sprinkle', 'apprehensive', 'companion', 'farmer', 'stumble', 'buff', 'buffet', 'flipper', 'jewel', 'shovel', 'guacamole', 'crusher', 'cranberry', 'multiclad']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: baby .. neighbors: ['baby', 'head', 'pick', 'pain', 'short', 'older', 'watch', 'device', 'turn', 'test', 'wife', 'heat', 'control', 'awesome', 'throw', 'model', 'life', 'push', 'start', 'hate']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: weather .. neighbors: ['weather', 'wake', 'warmth', 'humidifier', 'fluff', 'roomba', 'charger', 'flight', 'eureka', 'loft', 'gram', 'sleeper', 'extension', 'flannel', 'cozy', 'thermostat', 'pant', 'twin', 'purifier', 'allergy']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: buffet .. neighbors: ['buffet', 'seafood', 'lick', 'deni', 'import', 'briefly', 'apprehensive', 'canola', 'rosemary', 'shave', 'addict', 'remainder', 'pusher', 'sculpture', 'vast', 'drizzle', 'equip', 'brine', 'romaine', 'lemonade']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: ninja .. neighbors: ['ninja', 'thaw', 'canola', 'fillet', 'chewy', 'mood', 'unhealthy', 'puck', 'lemonade', 'flavorful', 'trader', 'tail', 'nutrient', 'poacher', 'shave', 'sour', 'greek', 'tamp', 'deni', 'variation']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: fingernail .. neighbors: ['fingernail', 'mayonnaise', 'beginner', 'sculpture', 'hash', 'supervision', 'radish', 'fountain', 'expert', 'fingertip', 'mexican', 'hummus', 'cauliflower', 'parmesan', 'cavity', 'blanch', 'tail', 'equip', 'briefly', 'ronco']\n",
      "####################################################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.65 .. Rec_loss: 112.2 .. NELBO: 113.85\n",
      "Epoch: 61 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 111.9 .. NELBO: 113.56\n",
      "Epoch: 61 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 111.94 .. NELBO: 113.62\n",
      "Epoch: 61 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 111.9 .. NELBO: 113.57\n",
      "Epoch: 61 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 111.86 .. NELBO: 113.52\n",
      "Epoch: 61 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 111.45 .. NELBO: 113.11\n",
      "****************************************************************************************************\n",
      "Epoch----->61 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 111.48 .. NELBO: 113.14\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 892.4\n",
      "****************************************************************************************************\n",
      "Epoch: 62 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 112.0 .. NELBO: 113.66\n",
      "Epoch: 62 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 112.44 .. NELBO: 114.11\n",
      "Epoch: 62 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 111.88 .. NELBO: 113.56\n",
      "Epoch: 62 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 111.76 .. NELBO: 113.44\n",
      "Epoch: 62 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 111.58 .. NELBO: 113.26\n",
      "Epoch: 62 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 111.8 .. NELBO: 113.47\n",
      "****************************************************************************************************\n",
      "Epoch----->62 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 111.42 .. NELBO: 113.08\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 889.2\n",
      "****************************************************************************************************\n",
      "Epoch: 63 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.63 .. Rec_loss: 110.65 .. NELBO: 112.28\n",
      "Epoch: 63 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 111.19 .. NELBO: 112.85\n",
      "Epoch: 63 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.69 .. Rec_loss: 111.36 .. NELBO: 113.05\n",
      "Epoch: 63 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.69 .. Rec_loss: 111.45 .. NELBO: 113.14\n",
      "Epoch: 63 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 111.58 .. NELBO: 113.25\n",
      "Epoch: 63 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 111.42 .. NELBO: 113.08\n",
      "****************************************************************************************************\n",
      "Epoch----->63 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 111.44 .. NELBO: 113.11\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 888.6\n",
      "****************************************************************************************************\n",
      "Epoch: 64 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.71 .. Rec_loss: 110.84 .. NELBO: 112.55\n",
      "Epoch: 64 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.69 .. Rec_loss: 111.18 .. NELBO: 112.87\n",
      "Epoch: 64 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 111.93 .. NELBO: 113.59\n",
      "Epoch: 64 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.64 .. Rec_loss: 111.23 .. NELBO: 112.87\n",
      "Epoch: 64 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.65 .. Rec_loss: 111.36 .. NELBO: 113.01\n",
      "Epoch: 64 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 111.33 .. NELBO: 112.99\n",
      "****************************************************************************************************\n",
      "Epoch----->64 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 111.41 .. NELBO: 113.08\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 887.8\n",
      "****************************************************************************************************\n",
      "Epoch: 65 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.63 .. Rec_loss: 109.88 .. NELBO: 111.51\n",
      "Epoch: 65 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.65 .. Rec_loss: 111.72 .. NELBO: 113.37\n",
      "Epoch: 65 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.64 .. Rec_loss: 111.66 .. NELBO: 113.3\n",
      "Epoch: 65 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 111.54 .. NELBO: 113.2\n",
      "Epoch: 65 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 111.74 .. NELBO: 113.41\n",
      "Epoch: 65 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 111.35 .. NELBO: 113.01\n",
      "****************************************************************************************************\n",
      "Epoch----->65 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 111.4 .. NELBO: 113.06\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 889.2\n",
      "****************************************************************************************************\n",
      "Epoch: 66 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.7 .. Rec_loss: 111.0 .. NELBO: 112.7\n",
      "Epoch: 66 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.72 .. Rec_loss: 111.23 .. NELBO: 112.95\n",
      "Epoch: 66 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.72 .. Rec_loss: 110.98 .. NELBO: 112.7\n",
      "Epoch: 66 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.72 .. Rec_loss: 111.34 .. NELBO: 113.06\n",
      "Epoch: 66 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.7 .. Rec_loss: 111.52 .. NELBO: 113.22\n",
      "Epoch: 66 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 111.47 .. NELBO: 113.15\n",
      "****************************************************************************************************\n",
      "Epoch----->66 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 111.4 .. NELBO: 113.08\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 887.2\n",
      "****************************************************************************************************\n",
      "Epoch: 67 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.72 .. Rec_loss: 112.25 .. NELBO: 113.97\n",
      "Epoch: 67 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.72 .. Rec_loss: 111.93 .. NELBO: 113.65\n",
      "Epoch: 67 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.7 .. Rec_loss: 111.53 .. NELBO: 113.23\n",
      "Epoch: 67 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.69 .. Rec_loss: 111.95 .. NELBO: 113.64\n",
      "Epoch: 67 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 111.32 .. NELBO: 113.0\n",
      "Epoch: 67 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 111.26 .. NELBO: 112.93\n",
      "****************************************************************************************************\n",
      "Epoch----->67 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 111.38 .. NELBO: 113.05\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 887.5\n",
      "****************************************************************************************************\n",
      "Epoch: 68 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 111.05 .. NELBO: 112.72\n",
      "Epoch: 68 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 111.96 .. NELBO: 113.63\n",
      "Epoch: 68 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 111.75 .. NELBO: 113.43\n",
      "Epoch: 68 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 111.52 .. NELBO: 113.2\n",
      "Epoch: 68 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 111.48 .. NELBO: 113.15\n",
      "Epoch: 68 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 111.31 .. NELBO: 112.98\n",
      "****************************************************************************************************\n",
      "Epoch----->68 .. LR: 0.005 .. KL_theta: 1.67 .. Rec_loss: 111.39 .. NELBO: 113.06\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 885.1\n",
      "****************************************************************************************************\n",
      "Epoch: 69 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.81 .. Rec_loss: 111.87 .. NELBO: 113.68\n",
      "Epoch: 69 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.74 .. Rec_loss: 111.54 .. NELBO: 113.28\n",
      "Epoch: 69 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.69 .. Rec_loss: 111.5 .. NELBO: 113.19\n",
      "Epoch: 69 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 111.07 .. NELBO: 112.75\n",
      "Epoch: 69 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.7 .. Rec_loss: 111.14 .. NELBO: 112.84\n",
      "Epoch: 69 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.71 .. Rec_loss: 111.07 .. NELBO: 112.78\n",
      "****************************************************************************************************\n",
      "Epoch----->69 .. LR: 0.005 .. KL_theta: 1.72 .. Rec_loss: 111.34 .. NELBO: 113.06\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 888.1\n",
      "****************************************************************************************************\n",
      "Epoch: 70 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.62 .. Rec_loss: 111.04 .. NELBO: 112.66\n",
      "Epoch: 70 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.63 .. Rec_loss: 110.77 .. NELBO: 112.4\n",
      "Epoch: 70 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.66 .. Rec_loss: 110.49 .. NELBO: 112.15\n",
      "Epoch: 70 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 110.8 .. NELBO: 112.48\n",
      "Epoch: 70 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 111.15 .. NELBO: 112.83\n",
      "Epoch: 70 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 111.28 .. NELBO: 112.96\n",
      "****************************************************************************************************\n",
      "Epoch----->70 .. LR: 0.005 .. KL_theta: 1.68 .. Rec_loss: 111.38 .. NELBO: 113.06\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 887.1\n",
      "****************************************************************************************************\n",
      "####################################################################################################\n",
      "Visualize topics...\n",
      "Topic 0: ['color', 'price', 'nice', 'item', 'great', 'product', 'good', 'space', 'towel']\n",
      "Topic 1: ['size', 'great', 'good', 'work', 'nice', 'plastic', 'quality', 'glass', 'bowl']\n",
      "Topic 2: ['coffee', 'water', 'work', 'time', 'great', 'easy', 'filter', 'clean', 'machine']\n",
      "Topic 3: ['knife', 'cook', 'clean', 'great', 'easy', 'work', 'stick', 'time', 'good']\n",
      "Topic 4: ['work', 'great', 'time', 'good', 'vacuum', 'room', 'clean', 'soft', 'purchase']\n",
      "####################################################################################################\n",
      "Visualize word embeddings by using output embedding matrix\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: cleaner .. neighbors: ['cleaner', 'noise', 'quiet', 'odor', 'heater', 'dust', 'battery', 'foam', 'carpet', 'pillow', 'dirt', 'mattress', 'sleep', 'vacuum', 'blanket', 'count', 'hair', 'powerful', 'comforter', 'night']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: refrigerate .. neighbors: ['refrigerate', 'alton', 'november', 'lifestyle', 'explode', 'buffet', 'amco', 'tonight', 'bind', 'marry', 'intention', 'cleanser', 'yeast', 'cranberry', 'cleave', 'edible', 'enhance', 'tbsp', 'pace', 'registry']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: tupperware .. neighbors: ['tupperware', 'mason', 'popsicle', 'sealer', 'pourer', 'stuffer', 'conversation', 'appetizer', 'bento', 'chiller', 'corkscrew', 'improve', 'cereal', 'pyrex', 'lunchbox', 'brittle', 'decanter', 'champagne', 'rubbermaid', 'potluck']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: curry .. neighbors: ['curry', 'stumble', 'edible', 'lick', 'leach', 'cranberry', 'intention', 'eater', 'buffet', 'worthy', 'fondue', 'watermelon', 'flipper', 'romaine', 'barrel', 'shovel', 'sprinkle', 'buff', 'jewel', 'slender']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: baby .. neighbors: ['baby', 'head', 'pick', 'hate', 'test', 'pain', 'wife', 'life', 'throw', 'turn', 'world', 'comfortable', 'lose', 'watch', 'amaze', 'start', 'device', 'control', 'older', 'feature']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: weather .. neighbors: ['weather', 'wake', 'twin', 'humidifier', 'fluff', 'loft', 'pillowcase', 'relax', 'charger', 'flannel', 'cozy', 'sleeper', 'alarm', 'elastic', 'thermostat', 'honeywell', 'lady', 'extension', 'warmth', 'allergy']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: buffet .. neighbors: ['buffet', 'leach', 'registry', 'romaine', 'lick', 'edible', 'stumble', 'cranberry', 'snapware', 'refrigerate', 'drizzle', 'curry', 'intention', 'explode', 'lifestyle', 'alton', 'eater', 'microwavable', 'cancer', 'condiment']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: ninja .. neighbors: ['ninja', 'canola', 'thaw', 'mood', 'chewy', 'unhealthy', 'tail', 'leaky', 'lemonade', 'flavorful', 'puck', 'equip', 'variation', 'concoction', 'submerge', 'trader', 'harvest', 'deni', 'poacher', 'pusher']\n",
      "vectors:  (3951, 300)\n",
      "query:  (300,)\n",
      "word: fingernail .. neighbors: ['fingernail', 'saut', 'ronco', 'beginner', 'omega', 'cavity', 'mayonnaise', 'fibrox', 'fingertip', 'hummus', 'alright', 'slaw', 'quesadilla', 'hash', 'jalapeno', 'jiffy', 'pumpkin', 'characteristic', 'parmesan', 'cauliflower']\n",
      "####################################################################################################\n",
      "Epoch: 71 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.77 .. Rec_loss: 111.56 .. NELBO: 113.33\n",
      "Epoch: 71 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.76 .. Rec_loss: 110.94 .. NELBO: 112.7\n",
      "Epoch: 71 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.74 .. Rec_loss: 110.96 .. NELBO: 112.7\n",
      "Epoch: 71 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.71 .. Rec_loss: 110.85 .. NELBO: 112.56\n",
      "Epoch: 71 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.7 .. Rec_loss: 111.3 .. NELBO: 113.0\n",
      "Epoch: 71 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.71 .. Rec_loss: 111.28 .. NELBO: 112.99\n",
      "****************************************************************************************************\n",
      "Epoch----->71 .. LR: 0.005 .. KL_theta: 1.71 .. Rec_loss: 111.32 .. NELBO: 113.03\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 884.0\n",
      "****************************************************************************************************\n",
      "Epoch: 72 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.75 .. Rec_loss: 110.38 .. NELBO: 112.13\n",
      "Epoch: 72 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.72 .. Rec_loss: 111.01 .. NELBO: 112.73\n",
      "Epoch: 72 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.7 .. Rec_loss: 111.18 .. NELBO: 112.88\n",
      "Epoch: 72 .. batch: 8/14 .. LR: 0.005 .. KL_theta: 1.7 .. Rec_loss: 111.27 .. NELBO: 112.97\n",
      "Epoch: 72 .. batch: 10/14 .. LR: 0.005 .. KL_theta: 1.7 .. Rec_loss: 111.29 .. NELBO: 112.99\n",
      "Epoch: 72 .. batch: 12/14 .. LR: 0.005 .. KL_theta: 1.7 .. Rec_loss: 111.14 .. NELBO: 112.84\n",
      "****************************************************************************************************\n",
      "Epoch----->72 .. LR: 0.005 .. KL_theta: 1.7 .. Rec_loss: 111.34 .. NELBO: 113.04\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "VAL Doc Completion PPL: 886.2\n",
      "****************************************************************************************************\n",
      "Epoch: 73 .. batch: 2/14 .. LR: 0.005 .. KL_theta: 1.69 .. Rec_loss: 110.54 .. NELBO: 112.23\n",
      "Epoch: 73 .. batch: 4/14 .. LR: 0.005 .. KL_theta: 1.7 .. Rec_loss: 111.1 .. NELBO: 112.8\n",
      "Epoch: 73 .. batch: 6/14 .. LR: 0.005 .. KL_theta: 1.71 .. Rec_loss: 111.66 .. NELBO: 113.37\n"
     ]
    }
   ],
   "source": [
    "if args.mode == 'train':\n",
    "    ## train model on data \n",
    "    best_epoch = 0\n",
    "    best_val_ppl = 1e9\n",
    "    all_val_ppls = []\n",
    "    print('\\n')\n",
    "    print('Visualizing model quality before training...')\n",
    "    visualize(model)\n",
    "    print('\\n')\n",
    "    for epoch in range(1, args.epochs):\n",
    "        train(epoch)\n",
    "        val_ppl = evaluate(model, 'val')\n",
    "        if val_ppl < best_val_ppl:\n",
    "            with open(ckpt, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_epoch = epoch\n",
    "            best_val_ppl = val_ppl\n",
    "        else:\n",
    "            ## check whether to anneal lr\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "            if args.anneal_lr and (len(all_val_ppls) > args.nonmono and val_ppl > min(all_val_ppls[:-args.nonmono]) and lr > 1e-5):\n",
    "                optimizer.param_groups[0]['lr'] /= args.lr_factor\n",
    "        if epoch % args.visualize_every == 0:\n",
    "            visualize(model)\n",
    "        all_val_ppls.append(val_ppl)\n",
    "    with open(ckpt, 'rb') as f:\n",
    "        model = torch.load(f)\n",
    "    model = model.to(device)\n",
    "    val_ppl = evaluate(model, 'val')\n",
    "else:   \n",
    "    with open(ckpt, 'rb') as f:\n",
    "        model = torch.load(f)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ## get document completion perplexities\n",
    "        test_ppl = evaluate(model, 'test', tc=args.tc, td=args.td)\n",
    "\n",
    "        ## get most used topics\n",
    "        indices = torch.tensor(range(args.num_docs_train))\n",
    "        indices = torch.split(indices, args.batch_size)\n",
    "        thetaAvg = torch.zeros(1, args.num_topics).to(device)\n",
    "        thetaWeightedAvg = torch.zeros(1, args.num_topics).to(device)\n",
    "        cnt = 0\n",
    "        for idx, ind in enumerate(indices):\n",
    "            data_batch = data.get_batch(train_tokens, train_counts, ind, args.vocab_size, device)\n",
    "            sums = data_batch.sum(1).unsqueeze(1)\n",
    "            cnt += sums.sum(0).squeeze().cpu().numpy()\n",
    "            if args.bow_norm:\n",
    "                normalized_data_batch = data_batch / sums\n",
    "            else:\n",
    "                normalized_data_batch = data_batch\n",
    "            theta, _ = model.get_theta(normalized_data_batch)\n",
    "            thetaAvg += theta.sum(0).unsqueeze(0) / args.num_docs_train\n",
    "            weighed_theta = sums * theta\n",
    "            thetaWeightedAvg += weighed_theta.sum(0).unsqueeze(0)\n",
    "            if idx % 100 == 0 and idx > 0:\n",
    "                print('batch: {}/{}'.format(idx, len(indices)))\n",
    "        thetaWeightedAvg = thetaWeightedAvg.squeeze().cpu().numpy() / cnt\n",
    "        print('\\nThe 10 most used topics are {}'.format(thetaWeightedAvg.argsort()[::-1][:10]))\n",
    "\n",
    "        ## show topics\n",
    "        beta = model.get_beta()\n",
    "        topic_indices = list(np.random.choice(args.num_topics, 10)) # 10 random topics\n",
    "        print('\\n')\n",
    "        for k in range(args.num_topics):#topic_indices:\n",
    "            gamma = beta[k]\n",
    "            top_words = list(gamma.cpu().numpy().argsort()[-args.num_words+1:][::-1])\n",
    "            topic_words = [vocab[a] for a in top_words]\n",
    "            print('Topic {}: {}'.format(k, topic_words))\n",
    "\n",
    "        if args.train_embeddings:\n",
    "            ## show etm embeddings \n",
    "            try:\n",
    "                rho_etm = model.rho.weight.cpu()\n",
    "            except:\n",
    "                rho_etm = model.rho.cpu()\n",
    "            queries = ['cleaner', 'refrigerate', 'tupperware', 'curry', 'baby', 'weather', 'buffet', \n",
    "                            'ninja', 'fingernail']\n",
    "            print('\\n')\n",
    "            print('ETM embeddings...')\n",
    "            for word in queries:\n",
    "                print('word: {} .. etm neighbors: {}'.format(word, nearest_neighbors(word, rho_etm, vocab)))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, 'val', tc=args.tc, td=args.td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
